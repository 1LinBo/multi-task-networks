{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the second multi-task network\n",
    "\n",
    "In this notebook we introduce the use of the second multi-task network through an example dataset (TCGA-BRCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import related packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from pycox.models.utils import pad_col\n",
    "from pycox.preprocessing.label_transforms import LabTransDiscreteTime\n",
    "from pycox import models\n",
    "from typing import Tuple\n",
    "from torch import Tensor\n",
    "from pycox.models import utils\n",
    "from torchtuples import TupleTree\n",
    "from scipy.interpolate import UnivariateSpline\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, '/')\n",
    "from eval import EvalSurv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some seeds to make this reproducable\n",
    "np.random.seed(123456)\n",
    "_ = torch.manual_seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COX5B</th>\n",
       "      <th>GLA</th>\n",
       "      <th>COL4A1</th>\n",
       "      <th>DNAL1</th>\n",
       "      <th>EHD4</th>\n",
       "      <th>EFNA1</th>\n",
       "      <th>XYLT1</th>\n",
       "      <th>TRA2B</th>\n",
       "      <th>NDUFA3</th>\n",
       "      <th>FLT1</th>\n",
       "      <th>...</th>\n",
       "      <th>AGL</th>\n",
       "      <th>P2RY13</th>\n",
       "      <th>IFNK</th>\n",
       "      <th>CALR</th>\n",
       "      <th>SNRPE</th>\n",
       "      <th>PVR</th>\n",
       "      <th>event2</th>\n",
       "      <th>T2</th>\n",
       "      <th>event1</th>\n",
       "      <th>T1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.85</td>\n",
       "      <td>10.30</td>\n",
       "      <td>13.51</td>\n",
       "      <td>8.84</td>\n",
       "      <td>9.43</td>\n",
       "      <td>10.75</td>\n",
       "      <td>8.42</td>\n",
       "      <td>11.32</td>\n",
       "      <td>7.79</td>\n",
       "      <td>9.84</td>\n",
       "      <td>...</td>\n",
       "      <td>11.05</td>\n",
       "      <td>5.23</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.15</td>\n",
       "      <td>9.45</td>\n",
       "      <td>9.86</td>\n",
       "      <td>0</td>\n",
       "      <td>4047</td>\n",
       "      <td>1</td>\n",
       "      <td>1808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.87</td>\n",
       "      <td>8.59</td>\n",
       "      <td>13.60</td>\n",
       "      <td>7.53</td>\n",
       "      <td>9.79</td>\n",
       "      <td>10.31</td>\n",
       "      <td>7.11</td>\n",
       "      <td>11.44</td>\n",
       "      <td>10.27</td>\n",
       "      <td>9.63</td>\n",
       "      <td>...</td>\n",
       "      <td>9.02</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.13</td>\n",
       "      <td>9.40</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0</td>\n",
       "      <td>4005</td>\n",
       "      <td>0</td>\n",
       "      <td>4005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.36</td>\n",
       "      <td>9.26</td>\n",
       "      <td>14.11</td>\n",
       "      <td>7.55</td>\n",
       "      <td>10.34</td>\n",
       "      <td>11.67</td>\n",
       "      <td>8.44</td>\n",
       "      <td>11.27</td>\n",
       "      <td>9.74</td>\n",
       "      <td>9.83</td>\n",
       "      <td>...</td>\n",
       "      <td>11.96</td>\n",
       "      <td>6.24</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.60</td>\n",
       "      <td>10.27</td>\n",
       "      <td>9.52</td>\n",
       "      <td>0</td>\n",
       "      <td>1474</td>\n",
       "      <td>0</td>\n",
       "      <td>1474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.90</td>\n",
       "      <td>13.71</td>\n",
       "      <td>13.19</td>\n",
       "      <td>8.65</td>\n",
       "      <td>10.73</td>\n",
       "      <td>11.42</td>\n",
       "      <td>8.83</td>\n",
       "      <td>11.25</td>\n",
       "      <td>10.05</td>\n",
       "      <td>9.68</td>\n",
       "      <td>...</td>\n",
       "      <td>9.09</td>\n",
       "      <td>6.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.27</td>\n",
       "      <td>10.13</td>\n",
       "      <td>7.84</td>\n",
       "      <td>0</td>\n",
       "      <td>1448</td>\n",
       "      <td>0</td>\n",
       "      <td>1448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.24</td>\n",
       "      <td>8.47</td>\n",
       "      <td>12.56</td>\n",
       "      <td>8.64</td>\n",
       "      <td>10.49</td>\n",
       "      <td>10.53</td>\n",
       "      <td>8.37</td>\n",
       "      <td>11.11</td>\n",
       "      <td>9.57</td>\n",
       "      <td>9.39</td>\n",
       "      <td>...</td>\n",
       "      <td>11.02</td>\n",
       "      <td>6.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.37</td>\n",
       "      <td>9.48</td>\n",
       "      <td>7.92</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4917 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   COX5B    GLA  COL4A1  DNAL1   EHD4  EFNA1  XYLT1  TRA2B  NDUFA3  FLT1  ...  \\\n",
       "0   9.85  10.30   13.51   8.84   9.43  10.75   8.42  11.32    7.79  9.84  ...   \n",
       "1  11.87   8.59   13.60   7.53   9.79  10.31   7.11  11.44   10.27  9.63  ...   \n",
       "2  11.36   9.26   14.11   7.55  10.34  11.67   8.44  11.27    9.74  9.83  ...   \n",
       "3  10.90  13.71   13.19   8.65  10.73  11.42   8.83  11.25   10.05  9.68  ...   \n",
       "4  10.24   8.47   12.56   8.64  10.49  10.53   8.37  11.11    9.57  9.39  ...   \n",
       "\n",
       "     AGL  P2RY13  IFNK   CALR  SNRPE   PVR  event2    T2  event1    T1  \n",
       "0  11.05    5.23   0.0  15.15   9.45  9.86       0  4047       1  1808  \n",
       "1   9.02    5.85   0.0  14.13   9.40  8.22       0  4005       0  4005  \n",
       "2  11.96    6.24   0.0  14.60  10.27  9.52       0  1474       0  1474  \n",
       "3   9.09    6.04   0.0  14.27  10.13  7.84       0  1448       0  1448  \n",
       "4  11.02    6.27   0.0  14.37   9.48  7.92       0   348       0   348  \n",
       "\n",
       "[5 rows x 4917 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "file_path = 'BRCA.txt'\n",
    "\n",
    "df = pd.read_csv(file_path, sep='\\t', header=0)\n",
    "\n",
    "# Leaving only the genetic data associated with the 186KEGG pathway\n",
    "def parse_kegg_file(file_path):\n",
    "    kegg_data = {}\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            if line.startswith('KEGG'):\n",
    "                parts = line.strip().split('\\t')\n",
    "                pathway_name = parts[0]\n",
    "                genes = parts[2:] if len(parts) > 2 else []\n",
    "                kegg_data[pathway_name] = genes\n",
    "    return kegg_data\n",
    "\n",
    "file_path = 'kegg_legacy.txt'\n",
    "kegg_pathways = parse_kegg_file(file_path)\n",
    "\n",
    "all_genes = set()\n",
    "\n",
    "for genes in kegg_pathways.values():\n",
    "    all_genes.update(genes)\n",
    "\n",
    "genes_columns = [gene for gene in all_genes if gene in df.columns]\n",
    "\n",
    "filtered_df_train = df[genes_columns]\n",
    "\n",
    "filtered_kegg_pathways = {}\n",
    "for pathway, genes in kegg_pathways.items():\n",
    "    filtered_genes = [gene for gene in genes if gene in genes_columns]\n",
    "    filtered_kegg_pathways[pathway] = filtered_genes\n",
    "\n",
    "concatenated_df = pd.concat([filtered_df_train, df.iloc[:,-4:]], axis=1)\n",
    "\n",
    "df_train = concatenated_df\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sparse connection layer mask matrix\n",
    "num_pathways = len(filtered_kegg_pathways)\n",
    "num_genes = len(genes_columns)\n",
    "\n",
    "mask = torch.zeros(num_pathways, num_genes, dtype=torch.bool)\n",
    "\n",
    "gene_to_index = {gene: idx for idx, gene in enumerate(genes_columns)}\n",
    "\n",
    "for pathway_idx, (pathway, genes) in enumerate(filtered_kegg_pathways.items()):\n",
    "    for gene in genes:\n",
    "        if gene in gene_to_index:\n",
    "            gene_idx = gene_to_index[gene]\n",
    "            mask[pathway_idx, gene_idx] = 1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COX5B',\n",
       " 'GLA',\n",
       " 'COL4A1',\n",
       " 'DNAL1',\n",
       " 'EHD4',\n",
       " 'EFNA1',\n",
       " 'XYLT1',\n",
       " 'TRA2B',\n",
       " 'NDUFA3',\n",
       " 'FLT1',\n",
       " 'L1CAM',\n",
       " 'TREH',\n",
       " 'F11R',\n",
       " 'CDC7',\n",
       " 'OR5M3',\n",
       " 'UGT8',\n",
       " 'TNFSF18',\n",
       " 'ACACA',\n",
       " 'ENTPD1',\n",
       " 'ACIN1',\n",
       " 'OR5P3',\n",
       " 'GSTA3',\n",
       " 'CLCA4',\n",
       " 'PPT1',\n",
       " 'CTLA4',\n",
       " 'B3GALT2',\n",
       " 'ADSL',\n",
       " 'MTHFS',\n",
       " 'BMP5',\n",
       " 'MAN2B1',\n",
       " 'OR5AK2',\n",
       " 'STAM',\n",
       " 'LTB4R',\n",
       " 'HNRNPA1',\n",
       " 'ACTN4',\n",
       " 'TAF10',\n",
       " 'MOS',\n",
       " 'AP1S3',\n",
       " 'ATP6V1B2',\n",
       " 'TBP',\n",
       " 'GPX3',\n",
       " 'OR6M1',\n",
       " 'FSHB',\n",
       " 'FLT4',\n",
       " 'MGAT4A',\n",
       " 'IL13RA1',\n",
       " 'GPX5',\n",
       " 'SPAM1',\n",
       " 'HCST',\n",
       " 'TNFRSF10B',\n",
       " 'FGF17',\n",
       " 'RPS6KA2',\n",
       " 'MMP2',\n",
       " 'ITGB2',\n",
       " 'NADK',\n",
       " 'NDUFA4L2',\n",
       " 'FBXW8',\n",
       " 'ATP6V1E2',\n",
       " 'C7',\n",
       " 'MANBA',\n",
       " 'RCOR1',\n",
       " 'BMP4',\n",
       " 'GNG7',\n",
       " 'TAS2R31',\n",
       " 'ACADM',\n",
       " 'COX6A2',\n",
       " 'FPGS',\n",
       " 'DBI',\n",
       " 'CREBBP',\n",
       " 'RFK',\n",
       " 'OSMR',\n",
       " 'TAT',\n",
       " 'TAS2R7',\n",
       " 'OR6C65',\n",
       " 'SGSH',\n",
       " 'APH1A',\n",
       " 'ARAP1',\n",
       " 'PGP',\n",
       " 'HPSE',\n",
       " 'OR2M5',\n",
       " 'OR52B4',\n",
       " 'VAMP2',\n",
       " 'DUSP16',\n",
       " 'ITPA',\n",
       " 'NCK2',\n",
       " 'TLN1',\n",
       " 'PSMF1',\n",
       " 'RPS10',\n",
       " 'SLC18A2',\n",
       " 'ZFYVE16',\n",
       " 'CANX',\n",
       " 'OR56A1',\n",
       " 'PDE4A',\n",
       " 'CPT1B',\n",
       " 'UBE2Q2',\n",
       " 'GPI',\n",
       " 'OR4F15',\n",
       " 'UBE2J2',\n",
       " 'E2F4',\n",
       " 'ADCY7',\n",
       " 'GABRA5',\n",
       " 'PSMC5',\n",
       " 'SGCG',\n",
       " 'IL20RA',\n",
       " 'CKMT1A',\n",
       " 'IRS2',\n",
       " 'MGAT5',\n",
       " 'DTYMK',\n",
       " 'OR7A5',\n",
       " 'DSG2',\n",
       " 'CHAD',\n",
       " 'NLRP3',\n",
       " 'PKP2',\n",
       " 'EME1',\n",
       " 'PLA2G4A',\n",
       " 'NT5C2',\n",
       " 'IL3',\n",
       " 'RAC3',\n",
       " 'FLNC',\n",
       " 'OR2L13',\n",
       " 'CASP8',\n",
       " 'NFKBIB',\n",
       " 'KLKB1',\n",
       " 'SSH3',\n",
       " 'GBA3',\n",
       " 'BRS3',\n",
       " 'PNP',\n",
       " 'SETD7',\n",
       " 'ATG12',\n",
       " 'BTRC',\n",
       " 'IL11',\n",
       " 'PIGT',\n",
       " 'EPHA8',\n",
       " 'POLA2',\n",
       " 'EGLN2',\n",
       " 'PRPF6',\n",
       " 'EXOSC4',\n",
       " 'LHCGR',\n",
       " 'GALNT12',\n",
       " 'NLGN3',\n",
       " 'POLA1',\n",
       " 'RDH16',\n",
       " 'HNMT',\n",
       " 'PRPF8',\n",
       " 'TAS2R43',\n",
       " 'PRPF3',\n",
       " 'DNASE2',\n",
       " 'CACNA1A',\n",
       " 'CRHR2',\n",
       " 'CDK6',\n",
       " 'PIWIL4',\n",
       " 'CHEK1',\n",
       " 'CD1E',\n",
       " 'IL18',\n",
       " 'ASIP',\n",
       " 'RPS15A',\n",
       " 'OR52K2',\n",
       " 'RNASEH2A',\n",
       " 'MAP2K4',\n",
       " 'AP3D1',\n",
       " 'MAML3',\n",
       " 'DYNLL2',\n",
       " 'SLC2A4',\n",
       " 'GAB1',\n",
       " 'CTSD',\n",
       " 'UCK2',\n",
       " 'NDUFS4',\n",
       " 'ATP1A4',\n",
       " 'ITGB4',\n",
       " 'PIK3C2B',\n",
       " 'BTK',\n",
       " 'PSMA3',\n",
       " 'LIF',\n",
       " 'IL1R2',\n",
       " 'FGR',\n",
       " 'SEMA3F',\n",
       " 'GABRA3',\n",
       " 'OR5K1',\n",
       " 'NME6',\n",
       " 'OR51M1',\n",
       " 'B4GALT5',\n",
       " 'ACER2',\n",
       " 'RNASEH1',\n",
       " 'RPL36AL',\n",
       " 'CACNA1F',\n",
       " 'EFNB2',\n",
       " 'EDNRB',\n",
       " 'MSH2',\n",
       " 'CARD6',\n",
       " 'BBOX1',\n",
       " 'GAA',\n",
       " 'ABCB11',\n",
       " 'NDUFB6',\n",
       " 'PTPN11',\n",
       " 'TCERG1',\n",
       " 'MYLK',\n",
       " 'OR8B4',\n",
       " 'DTX1',\n",
       " 'PGK2',\n",
       " 'ACTG1',\n",
       " 'CHMP2A',\n",
       " 'OR10J5',\n",
       " 'PLA2G4E',\n",
       " 'MYL10',\n",
       " 'INPP5B',\n",
       " 'RNASEH2B',\n",
       " 'ADH6',\n",
       " 'CYP2A7',\n",
       " 'HMOX2',\n",
       " 'GTF2H4',\n",
       " 'HYI',\n",
       " 'CTNNBIP1',\n",
       " 'ERBB3',\n",
       " 'WASF1',\n",
       " 'ZBTB17',\n",
       " 'TRHR',\n",
       " 'MLNR',\n",
       " 'MEF2C',\n",
       " 'CSNK1E',\n",
       " 'TNXB',\n",
       " 'C5AR1',\n",
       " 'SMPD4',\n",
       " 'BRCA1',\n",
       " 'CAMKK1',\n",
       " 'DAPP1',\n",
       " 'OR5V1',\n",
       " 'ULBP3',\n",
       " 'TPH2',\n",
       " 'GSTM1',\n",
       " 'CDKN2A',\n",
       " 'PLA2G12B',\n",
       " 'MMP14',\n",
       " 'CMPK1',\n",
       " 'F10',\n",
       " 'CDC5L',\n",
       " 'NUMBL',\n",
       " 'KMO',\n",
       " 'CAV2',\n",
       " 'FPR3',\n",
       " 'DUSP4',\n",
       " 'SYMPK',\n",
       " 'VASP',\n",
       " 'SUFU',\n",
       " 'KITLG',\n",
       " 'NLRP1',\n",
       " 'MAP3K8',\n",
       " 'PPARD',\n",
       " 'ITPK1',\n",
       " 'OR5D14',\n",
       " 'GNAQ',\n",
       " 'PARS2',\n",
       " 'SNRNP200',\n",
       " 'CPB2',\n",
       " 'OR51V1',\n",
       " 'GNGT2',\n",
       " 'GADD45A',\n",
       " 'FBXW11',\n",
       " 'CDK5R1',\n",
       " 'HTR2C',\n",
       " 'DHX8',\n",
       " 'IL20RB',\n",
       " 'GABRG3',\n",
       " 'AK5',\n",
       " 'ITGA4',\n",
       " 'OR1N2',\n",
       " 'OR52B6',\n",
       " 'PRKACA',\n",
       " 'NDUFS6',\n",
       " 'C1QA',\n",
       " 'FGF21',\n",
       " 'LPCAT3',\n",
       " 'SCD',\n",
       " 'CCND2',\n",
       " 'PDE4D',\n",
       " 'TAS2R42',\n",
       " 'BUD31',\n",
       " 'PDCD6IP',\n",
       " 'GLRA1',\n",
       " 'ACVR2B',\n",
       " 'PXMP2',\n",
       " 'GRK6',\n",
       " 'OR4C13',\n",
       " 'SCNN1G',\n",
       " 'PRKCZ',\n",
       " 'C4A',\n",
       " 'IMMP1L',\n",
       " 'LDHC',\n",
       " 'GSTA2',\n",
       " 'TAS2R3',\n",
       " 'ATP2B2',\n",
       " 'EPN1',\n",
       " 'DDO',\n",
       " 'CYFIP2',\n",
       " 'MUS81',\n",
       " 'ABLIM3',\n",
       " 'ITGAX',\n",
       " 'OPLAH',\n",
       " 'HPSE2',\n",
       " 'SDS',\n",
       " 'LCK',\n",
       " 'CD14',\n",
       " 'MCEE',\n",
       " 'CD47',\n",
       " 'RPL31',\n",
       " 'ANAPC7',\n",
       " 'CACNA2D1',\n",
       " 'CD72',\n",
       " 'DCP1A',\n",
       " 'IL6',\n",
       " 'ATP6V0D1',\n",
       " 'HPGDS',\n",
       " 'GTF2F2',\n",
       " 'PLD2',\n",
       " 'COL4A4',\n",
       " 'TAS1R1',\n",
       " 'IGSF5',\n",
       " 'PTPRM',\n",
       " 'SNCA',\n",
       " 'CYP1A1',\n",
       " 'ACTC1',\n",
       " 'IL4I1',\n",
       " 'ELOVL2',\n",
       " 'IL6R',\n",
       " 'OR51G2',\n",
       " 'OR8K5',\n",
       " 'TP53AIP1',\n",
       " 'STX1A',\n",
       " 'FST',\n",
       " 'PRICKLE2',\n",
       " 'TAS2R4',\n",
       " 'IL24',\n",
       " 'OR2T3',\n",
       " 'GCNT1',\n",
       " 'CREB1',\n",
       " 'FGF22',\n",
       " 'ATP6V0B',\n",
       " 'AMPD3',\n",
       " 'PFN3',\n",
       " 'TRPV1',\n",
       " 'CHRNE',\n",
       " 'KDSR',\n",
       " 'RASGRP4',\n",
       " 'CCL23',\n",
       " 'TMLHE',\n",
       " 'CISH',\n",
       " 'PIGY',\n",
       " 'PTGES',\n",
       " 'CTSZ',\n",
       " 'OR1M1',\n",
       " 'ACAA1',\n",
       " 'CD70',\n",
       " 'RPE65',\n",
       " 'SV2A',\n",
       " 'SLC4A4',\n",
       " 'RFC1',\n",
       " 'OR2C3',\n",
       " 'RPRM',\n",
       " 'FXYD4',\n",
       " 'TBL1XR1',\n",
       " 'OR4A5',\n",
       " 'LEFTY1',\n",
       " 'FADS2',\n",
       " 'HTR7',\n",
       " 'NT5C',\n",
       " 'SORT1',\n",
       " 'SPRY3',\n",
       " 'PDHA2',\n",
       " 'CXCR6',\n",
       " 'OR8J1',\n",
       " 'DNMT3A',\n",
       " 'CA7',\n",
       " 'PIWIL3',\n",
       " 'WNT7B',\n",
       " 'ATP6AP1',\n",
       " 'CD80',\n",
       " 'PRL',\n",
       " 'NCL',\n",
       " 'TACR2',\n",
       " 'PLA2G12A',\n",
       " 'ITPR1',\n",
       " 'AKR1A1',\n",
       " 'CDKN2D',\n",
       " 'ABO',\n",
       " 'RPL3',\n",
       " 'DDX3X',\n",
       " 'OR4F17',\n",
       " 'PXN',\n",
       " 'RAMP1',\n",
       " 'TAS2R41',\n",
       " 'HNF4G',\n",
       " 'STAT5B',\n",
       " 'MAP3K13',\n",
       " 'EXOSC1',\n",
       " 'FGB',\n",
       " 'PAPSS1',\n",
       " 'ACYP2',\n",
       " 'PLA2G10',\n",
       " 'CYP8B1',\n",
       " 'GUSB',\n",
       " 'FARS2',\n",
       " 'UBE2E1',\n",
       " 'ACAT1',\n",
       " 'MPHOSPH6',\n",
       " 'NR4A1',\n",
       " 'OR11G2',\n",
       " 'OR5L2',\n",
       " 'CDKN2C',\n",
       " 'SEC63',\n",
       " 'PHOSPHO1',\n",
       " 'PPP2R2C',\n",
       " 'OR10H5',\n",
       " 'UGT1A1',\n",
       " 'PTTG2',\n",
       " 'GGPS1',\n",
       " 'AIFM1',\n",
       " 'HBEGF',\n",
       " 'CAB39L',\n",
       " 'ILK',\n",
       " 'UBE2D1',\n",
       " 'UBE2H',\n",
       " 'MTHFD2L',\n",
       " 'ITGB3',\n",
       " 'RYR2',\n",
       " 'TTN',\n",
       " 'PPM1A',\n",
       " 'CYP26A1',\n",
       " 'AOC2',\n",
       " 'DNM2',\n",
       " 'LTA',\n",
       " 'SRC',\n",
       " 'ELK4',\n",
       " 'CD58',\n",
       " 'MCHR2',\n",
       " 'RPE',\n",
       " 'OR10G9',\n",
       " 'SGMS2',\n",
       " 'GAD2',\n",
       " 'IL25',\n",
       " 'CSNK1G1',\n",
       " 'HS3ST3B1',\n",
       " 'CSF3',\n",
       " 'PIGF',\n",
       " 'OR11H4',\n",
       " 'PDE4B',\n",
       " 'B3GALNT1',\n",
       " 'PRLHR',\n",
       " 'CD48',\n",
       " 'AP1B1',\n",
       " 'MAFA',\n",
       " 'UROS',\n",
       " 'ALDH7A1',\n",
       " 'CDK7',\n",
       " 'DRD1',\n",
       " 'BUB1B',\n",
       " 'P2RY4',\n",
       " 'FABP7',\n",
       " 'WNT1',\n",
       " 'TNNI3',\n",
       " 'TJAP1',\n",
       " 'GJA1',\n",
       " 'DCPS',\n",
       " 'IRAK4',\n",
       " 'PPP2R1B',\n",
       " 'GRK5',\n",
       " 'IRF5',\n",
       " 'CASP6',\n",
       " 'RPL36',\n",
       " 'OR7C2',\n",
       " 'ROBO1',\n",
       " 'SERPING1',\n",
       " 'GLI2',\n",
       " 'NAT1',\n",
       " 'PNPLA3',\n",
       " 'CLTCL1',\n",
       " 'IFNGR2',\n",
       " 'PSMD3',\n",
       " 'TNFSF14',\n",
       " 'KIR2DL4',\n",
       " 'GLRB',\n",
       " 'TOP3B',\n",
       " 'ENTPD4',\n",
       " 'PIGK',\n",
       " 'PLA2G15',\n",
       " 'SPTAN1',\n",
       " 'ATP6V0A2',\n",
       " 'PRPS1',\n",
       " 'LIMK2',\n",
       " 'ASMT',\n",
       " 'VAMP3',\n",
       " 'CDKN1A',\n",
       " 'CHRNB2',\n",
       " 'APAF1',\n",
       " 'PAFAH1B2',\n",
       " 'ACY1',\n",
       " 'LAMC1',\n",
       " 'FPGT',\n",
       " 'ADORA2A',\n",
       " 'RICTOR',\n",
       " 'NOX3',\n",
       " 'NRF1',\n",
       " 'FGA',\n",
       " 'COL1A1',\n",
       " 'TAS2R13',\n",
       " 'TICAM1',\n",
       " 'SEMA6C',\n",
       " 'VEGFA',\n",
       " 'CACNA1S',\n",
       " 'RPS4X',\n",
       " 'SOD2',\n",
       " 'ACOT7',\n",
       " 'PPA2',\n",
       " 'HYAL4',\n",
       " 'PIPOX',\n",
       " 'SF3B2',\n",
       " 'UCK1',\n",
       " 'UNC5C',\n",
       " 'IL13',\n",
       " 'FH',\n",
       " 'ITGAE',\n",
       " 'UBE2B',\n",
       " 'OR2T11',\n",
       " 'BRAF',\n",
       " 'C1QB',\n",
       " 'CDC25A',\n",
       " 'C1D',\n",
       " 'CAPN1',\n",
       " 'SMC3',\n",
       " 'PLCB3',\n",
       " 'GLRA3',\n",
       " 'DCK',\n",
       " 'RPL13',\n",
       " 'GNAI3',\n",
       " 'CMPK2',\n",
       " 'NSD1',\n",
       " 'NPBWR2',\n",
       " 'POLR2J',\n",
       " 'HMGCS1',\n",
       " 'OR5AS1',\n",
       " 'MARS2',\n",
       " 'DGKA',\n",
       " 'OR10A7',\n",
       " 'AACS',\n",
       " 'CRB3',\n",
       " 'PDE1C',\n",
       " 'MNX1',\n",
       " 'YWHAG',\n",
       " 'PRICKLE1',\n",
       " 'KHK',\n",
       " 'TXNRD2',\n",
       " 'RAB31',\n",
       " 'HS3ST2',\n",
       " 'OR4L1',\n",
       " 'ST3GAL3',\n",
       " 'THRA',\n",
       " 'PSMA5',\n",
       " 'MYH8',\n",
       " 'ICOSLG',\n",
       " 'FECH',\n",
       " 'UBE2K',\n",
       " 'GALNS',\n",
       " 'NOS1',\n",
       " 'YOD1',\n",
       " 'OR5T3',\n",
       " 'CDC40',\n",
       " 'INPP1',\n",
       " 'NAT2',\n",
       " 'CHST13',\n",
       " 'LAMC3',\n",
       " 'IL23A',\n",
       " 'CFL2',\n",
       " 'PROC',\n",
       " 'PIAS3',\n",
       " 'DNTT',\n",
       " 'SPRY4',\n",
       " 'THRB',\n",
       " 'AMDHD2',\n",
       " 'OR2AT4',\n",
       " 'DNM3',\n",
       " 'MAP3K14',\n",
       " 'MAP4K4',\n",
       " 'UGT2B15',\n",
       " 'OR8K3',\n",
       " 'B3GNT5',\n",
       " 'CSNK1A1',\n",
       " 'GABBR1',\n",
       " 'GIT1',\n",
       " 'SEPSECS',\n",
       " 'TGFA',\n",
       " 'SERPINB5',\n",
       " 'RFC2',\n",
       " 'MAP2K2',\n",
       " 'ALG5',\n",
       " 'RASGRP3',\n",
       " 'ERCC3',\n",
       " 'GFPT1',\n",
       " 'EXTL2',\n",
       " 'AGRN',\n",
       " 'BLM',\n",
       " 'CHPF',\n",
       " 'RBL2',\n",
       " 'DRD4',\n",
       " 'ITPR2',\n",
       " 'FMO4',\n",
       " 'RPS8',\n",
       " 'EXOG',\n",
       " 'SAT1',\n",
       " 'TNN',\n",
       " 'NOS3',\n",
       " 'OPRK1',\n",
       " 'OR51B4',\n",
       " 'GLI1',\n",
       " 'RPS6',\n",
       " 'UNC5B',\n",
       " 'TXK',\n",
       " 'MFNG',\n",
       " 'ALG10B',\n",
       " 'GABARAPL1',\n",
       " 'AMACR',\n",
       " 'HAO2',\n",
       " 'COX17',\n",
       " 'MMAB',\n",
       " 'RAP1B',\n",
       " 'AP1G1',\n",
       " 'IL10',\n",
       " 'PGK1',\n",
       " 'ICAM1',\n",
       " 'ZFYVE9',\n",
       " 'HACL1',\n",
       " 'RRAS2',\n",
       " 'OR5J2',\n",
       " 'VAV1',\n",
       " 'ID1',\n",
       " 'PAK3',\n",
       " 'OR10G2',\n",
       " 'OR1S2',\n",
       " 'B4GALNT1',\n",
       " 'PDE10A',\n",
       " 'OR2W3',\n",
       " 'OR6C3',\n",
       " 'FOXA3',\n",
       " 'PSME1',\n",
       " 'IRAK1',\n",
       " 'ARAP2',\n",
       " 'TFDP2',\n",
       " 'HMGB1',\n",
       " 'TAAR2',\n",
       " 'RHOBTB2',\n",
       " 'VAMP5',\n",
       " 'MYL9',\n",
       " 'STX10',\n",
       " 'ATP6V1C1',\n",
       " 'CALM1',\n",
       " 'XRCC3',\n",
       " 'RPL10L',\n",
       " 'CYP4F2',\n",
       " 'ACAT2',\n",
       " 'CS',\n",
       " 'CD82',\n",
       " 'APOE',\n",
       " 'NOTCH4',\n",
       " 'LPAR2',\n",
       " 'NEIL1',\n",
       " 'AVPR2',\n",
       " 'ALAS2',\n",
       " 'RNASE3',\n",
       " 'PIGU',\n",
       " 'YWHAE',\n",
       " 'HPRT1',\n",
       " 'MAPKAPK2',\n",
       " 'OR5A2',\n",
       " 'RPL23',\n",
       " 'NCR3',\n",
       " 'ENO3',\n",
       " 'ITGB1',\n",
       " 'OR1L4',\n",
       " 'DNMT1',\n",
       " 'NCK1',\n",
       " 'ADCY1',\n",
       " 'DHRS9',\n",
       " 'SLC25A6',\n",
       " 'PIGP',\n",
       " 'FZD10',\n",
       " 'C4BPA',\n",
       " 'AP3S2',\n",
       " 'TNFSF10',\n",
       " 'CTSG',\n",
       " 'UTS2R',\n",
       " 'LAP3',\n",
       " 'FADS1',\n",
       " 'INHBB',\n",
       " 'LBP',\n",
       " 'F2',\n",
       " 'SH3GLB2',\n",
       " 'PAK6',\n",
       " 'PNPT1',\n",
       " 'PFKFB2',\n",
       " 'CYP1A2',\n",
       " 'DIAPH3',\n",
       " 'B4GALT2',\n",
       " 'IL18RAP',\n",
       " 'RPL21',\n",
       " 'IQSEC2',\n",
       " 'GNB2',\n",
       " 'ADIPOR1',\n",
       " 'AWAT2',\n",
       " 'NLN',\n",
       " 'IQGAP2',\n",
       " 'OR8D2',\n",
       " 'RFC3',\n",
       " 'GUCA1B',\n",
       " 'ELANE',\n",
       " 'OR4C16',\n",
       " 'TAF13',\n",
       " 'HK1',\n",
       " 'DLG4',\n",
       " 'NOTCH1',\n",
       " 'OR6C70',\n",
       " 'BIRC5',\n",
       " 'RPS11',\n",
       " 'CXCL14',\n",
       " 'PLOD3',\n",
       " 'PPIH',\n",
       " 'CLDN7',\n",
       " 'MYH2',\n",
       " 'GPD1L',\n",
       " 'OR10Q1',\n",
       " 'NSDHL',\n",
       " 'F5',\n",
       " 'NBN',\n",
       " 'TAB3',\n",
       " 'FABP3',\n",
       " 'F3',\n",
       " 'FN1',\n",
       " 'OR2T12',\n",
       " 'CDC14B',\n",
       " 'ARHGEF12',\n",
       " 'OR5D13',\n",
       " 'ACSM2A',\n",
       " 'SARDH',\n",
       " 'SPIRE1',\n",
       " 'UMPS',\n",
       " 'LYPLA1',\n",
       " 'SDHA',\n",
       " 'HGS',\n",
       " 'CD226',\n",
       " 'SMO',\n",
       " 'VAMP4',\n",
       " 'CNTNAP2',\n",
       " 'IHH',\n",
       " 'PRPS1L1',\n",
       " 'SSTR5',\n",
       " 'IL21R',\n",
       " 'HNRNPA1L2',\n",
       " 'CDC25C',\n",
       " 'RPL6',\n",
       " 'SH3GL3',\n",
       " 'RASGRF2',\n",
       " 'EPB41L1',\n",
       " 'OR4C45',\n",
       " 'SOCS5',\n",
       " 'PDE6H',\n",
       " 'B3GNT2',\n",
       " 'GABARAPL2',\n",
       " 'UQCRFS1',\n",
       " 'B3GALT4',\n",
       " 'MDM2',\n",
       " 'RARA',\n",
       " 'IL1RAP',\n",
       " 'ALS2',\n",
       " 'LDLRAP1',\n",
       " 'ACSM3',\n",
       " 'ABCA4',\n",
       " 'SRP68',\n",
       " 'SNAP25',\n",
       " 'DDB1',\n",
       " 'FGF4',\n",
       " 'PLCD4',\n",
       " 'PGAM1',\n",
       " 'PTPN1',\n",
       " 'CCR10',\n",
       " 'CASP3',\n",
       " 'GLI3',\n",
       " 'ENTPD5',\n",
       " 'PDCD1',\n",
       " 'PLCG2',\n",
       " 'ST3GAL5',\n",
       " 'CASK',\n",
       " 'SEC61A1',\n",
       " 'CHST15',\n",
       " 'VPS28',\n",
       " 'GSTK1',\n",
       " 'BMPR1A',\n",
       " 'MAPK13',\n",
       " 'TUBA1A',\n",
       " 'PER3',\n",
       " 'OR10J1',\n",
       " 'FZD8',\n",
       " 'PIK3R3',\n",
       " 'PDHA1',\n",
       " 'RPLP1',\n",
       " 'P4HA1',\n",
       " 'PEX11G',\n",
       " 'PCYT2',\n",
       " 'PPP2R2D',\n",
       " 'CHIA',\n",
       " 'GABRB1',\n",
       " 'EPHB3',\n",
       " 'LPCAT1',\n",
       " 'MCM3',\n",
       " 'OR4D9',\n",
       " 'TRA2A',\n",
       " 'PSMD1',\n",
       " 'F7',\n",
       " 'NPR2',\n",
       " 'DVL1',\n",
       " 'OXA1L',\n",
       " 'TNFSF13',\n",
       " 'TBL1X',\n",
       " 'ATP2B1',\n",
       " 'SAE1',\n",
       " 'PTK2',\n",
       " 'DNA2',\n",
       " 'NNMT',\n",
       " 'AP1S1',\n",
       " 'PRSS1',\n",
       " 'NDUFS7',\n",
       " 'KDELR2',\n",
       " 'ALDOA',\n",
       " 'PARK7',\n",
       " 'DNALI1',\n",
       " 'PPM1D',\n",
       " 'TBXAS1',\n",
       " 'PIGA',\n",
       " 'E2F5',\n",
       " 'OR52I1',\n",
       " 'ODC1',\n",
       " 'CYP17A1',\n",
       " 'SUV39H1',\n",
       " 'NOTCH3',\n",
       " 'ARAP3',\n",
       " 'NEU4',\n",
       " 'SLIT1',\n",
       " 'CD37',\n",
       " 'DYNC1LI2',\n",
       " 'SH2D1A',\n",
       " 'P2RX7',\n",
       " 'GSTM2',\n",
       " 'OR4D11',\n",
       " 'FBXO2',\n",
       " 'GRM7',\n",
       " 'CACNA1I',\n",
       " 'RNF41',\n",
       " 'ACE',\n",
       " 'CHRM2',\n",
       " 'LSM6',\n",
       " 'QDPR',\n",
       " 'GK',\n",
       " 'PARD6G',\n",
       " 'OR2C1',\n",
       " 'UGT1A5',\n",
       " 'ALG1',\n",
       " 'CACNG2',\n",
       " 'RENBP',\n",
       " 'VDAC1',\n",
       " 'MYL12A',\n",
       " 'COX6B1',\n",
       " 'ACE2',\n",
       " 'AUH',\n",
       " 'IRF3',\n",
       " 'ACVR2A',\n",
       " 'OR6A2',\n",
       " 'CTSO',\n",
       " 'EXT1',\n",
       " 'MYH7B',\n",
       " 'MAGI2',\n",
       " 'CYP3A43',\n",
       " 'PKLR',\n",
       " 'PPP1R3D',\n",
       " 'CHRM3',\n",
       " 'OR5AN1',\n",
       " 'OR10S1',\n",
       " 'ABCB8',\n",
       " 'P2RY14',\n",
       " 'EIF4G1',\n",
       " 'NOTCH2',\n",
       " 'VPS4B',\n",
       " 'OR5L1',\n",
       " 'STK4',\n",
       " 'EXOSC8',\n",
       " 'GRIK2',\n",
       " 'JAG1',\n",
       " 'PPP1R3B',\n",
       " 'HDC',\n",
       " 'BST1',\n",
       " 'ACAP1',\n",
       " 'CDKN2B',\n",
       " 'MAPK12',\n",
       " 'PLXNA2',\n",
       " 'ADORA1',\n",
       " 'TAS2R14',\n",
       " 'F2RL3',\n",
       " 'HRH3',\n",
       " 'IMPDH1',\n",
       " 'IFNA6',\n",
       " 'WNT2B',\n",
       " 'TAS2R10',\n",
       " 'KCNMB4',\n",
       " 'LAT',\n",
       " 'ENPEP',\n",
       " 'SNAP23',\n",
       " 'CALD1',\n",
       " 'SESN2',\n",
       " 'CDC26',\n",
       " 'OR5M10',\n",
       " 'PLEKHO2',\n",
       " 'SUMF1',\n",
       " 'GOT2',\n",
       " 'CUL2',\n",
       " 'KCNMB1',\n",
       " 'RPS6KB1',\n",
       " 'SRD5A3',\n",
       " 'B4GALT7',\n",
       " 'POLR3B',\n",
       " 'RFT1',\n",
       " 'CHRNA9',\n",
       " 'MYL6B',\n",
       " 'EMD',\n",
       " 'PSMB9',\n",
       " 'BCL2',\n",
       " 'PRKCE',\n",
       " 'GGT5',\n",
       " 'IVD',\n",
       " 'OR2AE1',\n",
       " 'OR6Y1',\n",
       " 'EDC3',\n",
       " 'ERCC8',\n",
       " 'OR51T1',\n",
       " 'DVL3',\n",
       " 'POLE3',\n",
       " 'PSMA7',\n",
       " 'MAN2A1',\n",
       " 'KIR3DL2',\n",
       " 'MAML2',\n",
       " 'PSTK',\n",
       " 'HMGCS2',\n",
       " 'HS6ST1',\n",
       " 'EIF4E2',\n",
       " 'DPYD',\n",
       " 'RPS6KA5',\n",
       " 'PANK3',\n",
       " 'WIF1',\n",
       " 'ARHGEF1',\n",
       " 'MDH2',\n",
       " 'OR7G3',\n",
       " 'GNG10',\n",
       " 'DCXR',\n",
       " 'HGD',\n",
       " 'OR10V1',\n",
       " 'ST6GALNAC3',\n",
       " 'RPL5',\n",
       " 'ACSL5',\n",
       " 'LFNG',\n",
       " 'RAB11FIP2',\n",
       " 'OR51I2',\n",
       " 'RPL12',\n",
       " 'MBOAT2',\n",
       " 'MTOR',\n",
       " 'SHC4',\n",
       " 'RPA2',\n",
       " 'RFC5',\n",
       " 'L2HGDH',\n",
       " 'FGF19',\n",
       " 'GRM1',\n",
       " 'CNTF',\n",
       " 'RB1',\n",
       " 'NCAM2',\n",
       " 'PIP5K1B',\n",
       " 'OR2B3',\n",
       " 'COX6C',\n",
       " 'PTCRA',\n",
       " 'C9',\n",
       " 'ALPP',\n",
       " 'SOS2',\n",
       " 'MCHR1',\n",
       " 'PDGFRA',\n",
       " 'GRK7',\n",
       " 'ANPEP',\n",
       " 'NUDT19',\n",
       " 'CGN',\n",
       " 'DNM1',\n",
       " 'EIF4G3',\n",
       " 'FARSA',\n",
       " 'DPYS',\n",
       " 'PLN',\n",
       " 'ADH1B',\n",
       " 'OR5H6',\n",
       " 'MADCAM1',\n",
       " 'ULK2',\n",
       " 'PPP1R12A',\n",
       " 'CALML6',\n",
       " ...]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View all gene names\n",
    "xx = df_train.drop(columns=['event2','T2','event1','T1'])\n",
    "xx.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COX5B</th>\n",
       "      <th>GLA</th>\n",
       "      <th>COL4A1</th>\n",
       "      <th>DNAL1</th>\n",
       "      <th>EHD4</th>\n",
       "      <th>EFNA1</th>\n",
       "      <th>XYLT1</th>\n",
       "      <th>TRA2B</th>\n",
       "      <th>NDUFA3</th>\n",
       "      <th>FLT1</th>\n",
       "      <th>...</th>\n",
       "      <th>AGL</th>\n",
       "      <th>P2RY13</th>\n",
       "      <th>IFNK</th>\n",
       "      <th>CALR</th>\n",
       "      <th>SNRPE</th>\n",
       "      <th>PVR</th>\n",
       "      <th>event2</th>\n",
       "      <th>T2</th>\n",
       "      <th>event1</th>\n",
       "      <th>T1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9.85</td>\n",
       "      <td>10.30</td>\n",
       "      <td>13.51</td>\n",
       "      <td>8.84</td>\n",
       "      <td>9.43</td>\n",
       "      <td>10.75</td>\n",
       "      <td>8.42</td>\n",
       "      <td>11.32</td>\n",
       "      <td>7.79</td>\n",
       "      <td>9.84</td>\n",
       "      <td>...</td>\n",
       "      <td>11.05</td>\n",
       "      <td>5.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>15.15</td>\n",
       "      <td>9.45</td>\n",
       "      <td>9.86</td>\n",
       "      <td>0</td>\n",
       "      <td>4047</td>\n",
       "      <td>1</td>\n",
       "      <td>1808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11.87</td>\n",
       "      <td>8.59</td>\n",
       "      <td>13.60</td>\n",
       "      <td>7.53</td>\n",
       "      <td>9.79</td>\n",
       "      <td>10.31</td>\n",
       "      <td>7.11</td>\n",
       "      <td>11.44</td>\n",
       "      <td>10.27</td>\n",
       "      <td>9.63</td>\n",
       "      <td>...</td>\n",
       "      <td>9.02</td>\n",
       "      <td>5.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.13</td>\n",
       "      <td>9.40</td>\n",
       "      <td>8.22</td>\n",
       "      <td>0</td>\n",
       "      <td>4005</td>\n",
       "      <td>0</td>\n",
       "      <td>4005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11.36</td>\n",
       "      <td>9.26</td>\n",
       "      <td>14.11</td>\n",
       "      <td>7.55</td>\n",
       "      <td>10.34</td>\n",
       "      <td>11.67</td>\n",
       "      <td>8.44</td>\n",
       "      <td>11.27</td>\n",
       "      <td>9.74</td>\n",
       "      <td>9.83</td>\n",
       "      <td>...</td>\n",
       "      <td>11.96</td>\n",
       "      <td>6.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.60</td>\n",
       "      <td>10.27</td>\n",
       "      <td>9.52</td>\n",
       "      <td>0</td>\n",
       "      <td>1474</td>\n",
       "      <td>0</td>\n",
       "      <td>1474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10.84</td>\n",
       "      <td>9.76</td>\n",
       "      <td>12.59</td>\n",
       "      <td>8.63</td>\n",
       "      <td>10.35</td>\n",
       "      <td>11.83</td>\n",
       "      <td>8.96</td>\n",
       "      <td>11.33</td>\n",
       "      <td>9.73</td>\n",
       "      <td>9.33</td>\n",
       "      <td>...</td>\n",
       "      <td>12.05</td>\n",
       "      <td>7.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.22</td>\n",
       "      <td>10.20</td>\n",
       "      <td>8.03</td>\n",
       "      <td>0</td>\n",
       "      <td>1477</td>\n",
       "      <td>0</td>\n",
       "      <td>1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.57</td>\n",
       "      <td>8.41</td>\n",
       "      <td>11.27</td>\n",
       "      <td>8.20</td>\n",
       "      <td>9.46</td>\n",
       "      <td>10.06</td>\n",
       "      <td>6.11</td>\n",
       "      <td>11.38</td>\n",
       "      <td>9.96</td>\n",
       "      <td>8.26</td>\n",
       "      <td>...</td>\n",
       "      <td>9.07</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.54</td>\n",
       "      <td>10.56</td>\n",
       "      <td>10.26</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>10.75</td>\n",
       "      <td>9.18</td>\n",
       "      <td>11.59</td>\n",
       "      <td>8.35</td>\n",
       "      <td>9.90</td>\n",
       "      <td>11.95</td>\n",
       "      <td>7.59</td>\n",
       "      <td>11.05</td>\n",
       "      <td>9.91</td>\n",
       "      <td>9.24</td>\n",
       "      <td>...</td>\n",
       "      <td>9.56</td>\n",
       "      <td>6.27</td>\n",
       "      <td>0.56</td>\n",
       "      <td>13.94</td>\n",
       "      <td>10.13</td>\n",
       "      <td>8.69</td>\n",
       "      <td>0</td>\n",
       "      <td>347</td>\n",
       "      <td>0</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>10.30</td>\n",
       "      <td>8.14</td>\n",
       "      <td>13.49</td>\n",
       "      <td>8.38</td>\n",
       "      <td>10.61</td>\n",
       "      <td>10.64</td>\n",
       "      <td>9.51</td>\n",
       "      <td>11.12</td>\n",
       "      <td>8.35</td>\n",
       "      <td>10.08</td>\n",
       "      <td>...</td>\n",
       "      <td>9.81</td>\n",
       "      <td>6.94</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.57</td>\n",
       "      <td>9.37</td>\n",
       "      <td>9.44</td>\n",
       "      <td>0</td>\n",
       "      <td>467</td>\n",
       "      <td>0</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>10.26</td>\n",
       "      <td>8.47</td>\n",
       "      <td>13.67</td>\n",
       "      <td>8.86</td>\n",
       "      <td>10.80</td>\n",
       "      <td>11.37</td>\n",
       "      <td>9.81</td>\n",
       "      <td>11.12</td>\n",
       "      <td>9.24</td>\n",
       "      <td>10.19</td>\n",
       "      <td>...</td>\n",
       "      <td>10.21</td>\n",
       "      <td>7.53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.24</td>\n",
       "      <td>9.29</td>\n",
       "      <td>8.63</td>\n",
       "      <td>0</td>\n",
       "      <td>488</td>\n",
       "      <td>0</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>11.39</td>\n",
       "      <td>10.67</td>\n",
       "      <td>12.45</td>\n",
       "      <td>8.20</td>\n",
       "      <td>10.48</td>\n",
       "      <td>12.92</td>\n",
       "      <td>7.75</td>\n",
       "      <td>11.46</td>\n",
       "      <td>10.73</td>\n",
       "      <td>9.28</td>\n",
       "      <td>...</td>\n",
       "      <td>9.31</td>\n",
       "      <td>7.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14.27</td>\n",
       "      <td>10.75</td>\n",
       "      <td>9.11</td>\n",
       "      <td>0</td>\n",
       "      <td>3287</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>10.92</td>\n",
       "      <td>8.97</td>\n",
       "      <td>12.63</td>\n",
       "      <td>9.02</td>\n",
       "      <td>10.52</td>\n",
       "      <td>11.89</td>\n",
       "      <td>10.32</td>\n",
       "      <td>11.63</td>\n",
       "      <td>9.10</td>\n",
       "      <td>9.16</td>\n",
       "      <td>...</td>\n",
       "      <td>13.30</td>\n",
       "      <td>4.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.88</td>\n",
       "      <td>10.43</td>\n",
       "      <td>7.92</td>\n",
       "      <td>0</td>\n",
       "      <td>3256</td>\n",
       "      <td>0</td>\n",
       "      <td>3256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>692 rows × 4917 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      COX5B    GLA  COL4A1  DNAL1   EHD4  EFNA1  XYLT1  TRA2B  NDUFA3   FLT1  \\\n",
       "0      9.85  10.30   13.51   8.84   9.43  10.75   8.42  11.32    7.79   9.84   \n",
       "1     11.87   8.59   13.60   7.53   9.79  10.31   7.11  11.44   10.27   9.63   \n",
       "2     11.36   9.26   14.11   7.55  10.34  11.67   8.44  11.27    9.74   9.83   \n",
       "5     10.84   9.76   12.59   8.63  10.35  11.83   8.96  11.33    9.73   9.33   \n",
       "7     10.57   8.41   11.27   8.20   9.46  10.06   6.11  11.38    9.96   8.26   \n",
       "...     ...    ...     ...    ...    ...    ...    ...    ...     ...    ...   \n",
       "1074  10.75   9.18   11.59   8.35   9.90  11.95   7.59  11.05    9.91   9.24   \n",
       "1077  10.30   8.14   13.49   8.38  10.61  10.64   9.51  11.12    8.35  10.08   \n",
       "1078  10.26   8.47   13.67   8.86  10.80  11.37   9.81  11.12    9.24  10.19   \n",
       "1079  11.39  10.67   12.45   8.20  10.48  12.92   7.75  11.46   10.73   9.28   \n",
       "1080  10.92   8.97   12.63   9.02  10.52  11.89  10.32  11.63    9.10   9.16   \n",
       "\n",
       "      ...    AGL  P2RY13  IFNK   CALR  SNRPE    PVR  event2    T2  event1  \\\n",
       "0     ...  11.05    5.23  0.00  15.15   9.45   9.86       0  4047       1   \n",
       "1     ...   9.02    5.85  0.00  14.13   9.40   8.22       0  4005       0   \n",
       "2     ...  11.96    6.24  0.00  14.60  10.27   9.52       0  1474       0   \n",
       "5     ...  12.05    7.32  0.00  14.22  10.20   8.03       0  1477       0   \n",
       "7     ...   9.07    2.22  0.00  14.54  10.56  10.26       0   303       0   \n",
       "...   ...    ...     ...   ...    ...    ...    ...     ...   ...     ...   \n",
       "1074  ...   9.56    6.27  0.56  13.94  10.13   8.69       0   347       0   \n",
       "1077  ...   9.81    6.94  0.00  13.57   9.37   9.44       0   467       0   \n",
       "1078  ...  10.21    7.53  0.00  14.24   9.29   8.63       0   488       0   \n",
       "1079  ...   9.31    7.09  0.00  14.27  10.75   9.11       0  3287       1   \n",
       "1080  ...  13.30    4.06  0.00  13.88  10.43   7.92       0  3256       0   \n",
       "\n",
       "        T1  \n",
       "0     1808  \n",
       "1     4005  \n",
       "2     1474  \n",
       "5     1477  \n",
       "7      303  \n",
       "...    ...  \n",
       "1074   347  \n",
       "1077   467  \n",
       "1078   488  \n",
       "1079   181  \n",
       "1080  3256  \n",
       "\n",
       "[692 rows x 4917 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/test/validation split\n",
    "df_test = df_train.sample(frac=0.2)\n",
    "df_train = df_train.drop(df_test.index)\n",
    "df_val = df_train.sample(frac=0.2)\n",
    "df_train = df_train.drop(df_val.index)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariate preprocessing\n",
    "cols_standardize =  xx.columns.tolist()\n",
    "\n",
    "standardize = [([col], StandardScaler()) for col in cols_standardize]\n",
    "\n",
    "x_mapper = DataFrameMapper(standardize)\n",
    "\n",
    "x_train = x_mapper.fit_transform(df_train).astype('float32')\n",
    "x_val = x_mapper.transform(df_val).astype('float32')\n",
    "x_test = x_mapper.transform(df_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretization of survival times\n",
    "class LabTransform(LabTransDiscreteTime):\n",
    "    def transform(self, durations, events):\n",
    "        durations, is_event = super().transform(durations, events > 0)\n",
    "        events[is_event == 0] = 0\n",
    "        return durations, events.astype('int64')\n",
    "        \n",
    "num_durations = 10\n",
    "\n",
    "labtrans1 = LabTransform(num_durations, scheme='equidistant')\n",
    "get_target1 = lambda df: (df['T1'].values, df['event1'].values)\n",
    "\n",
    "T1_train = labtrans1.fit_transform(*get_target1(df_train))\n",
    "T1_val = labtrans1.transform(*get_target1(df_val))\n",
    "T1_test, event1_test = labtrans1.transform(*get_target1(df_test))\n",
    "\n",
    "labtrans2 = LabTransform(num_durations, scheme='equidistant')\n",
    "get_target2 = lambda df: (df['T2'].values, df['event2'].values)\n",
    "\n",
    "T2_train = labtrans2.fit_transform(*get_target2(df_train))\n",
    "T2_val = labtrans2.transform(*get_target2(df_val))\n",
    "# Discretization is not required because the prediction time is already a continuous value after spline interpolation when evaluated on the test set\n",
    "T2_test, event2_test = get_target2(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package the data into the input format required by the network later\n",
    "def index_to_1d(i, j, n):\n",
    "    \"\"\"\n",
    "    Converts a 2D index (i, j) from sets T1 and T2, each with elements ranging from 1 to n, to a 1D index.\n",
    "    \"\"\"\n",
    "    return i * n + j\n",
    "\n",
    "T_train = list(T1_train)\n",
    "T1_train_list = list(T1_train)\n",
    "T2_train_list = list(T2_train)\n",
    "T_train[0] = index_to_1d(T1_train_list[0], T2_train_list[0], num_durations)\n",
    "T_train[1] = index_to_1d(T1_train_list[1], T2_train_list[1], 2)\n",
    "T_train = tuple(T_train)\n",
    "\n",
    "T_val = list(T1_val)\n",
    "T1_val_list = list(T1_val)\n",
    "T2_val_list = list(T2_val)\n",
    "T_val[0] = index_to_1d(T1_val_list[0], T2_val_list[0], num_durations)\n",
    "T_val[1] = index_to_1d(T1_val_list[1], T2_val_list[1], 2)\n",
    "T_val = tuple(T_val)\n",
    "val = (x_val, T_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network architecture\n",
    "class MaskedLinearLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features, bias=True, mask=None):\n",
    "        super(MaskedLinearLayer, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = nn.Parameter(torch.Tensor(out_features, in_features))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        if bias:\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "        self.mask = mask if mask is not None else torch.ones(out_features, in_features)\n",
    "\n",
    "    def forward(self, input):\n",
    "        masked_weight = self.weight * self.mask\n",
    "        return nn.functional.linear(input, masked_weight, self.bias)\n",
    "\n",
    "class Multivariate_survival(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, num_nodes_shared, num_nodes_indiv, num_T1,\n",
    "                 out_features, batch_norm=True, dropout=None, mask=None):\n",
    "        super().__init__()\n",
    "        self.first_layer = MaskedLinearLayer(in_features, num_nodes_shared[0], mask=mask)\n",
    "        self.shared_net = tt.practical.MLPVanilla(\n",
    "            num_nodes_shared[0], num_nodes_shared[1:-1], num_nodes_shared[-1],\n",
    "            batch_norm, dropout,\n",
    "        )\n",
    "        self.risk_nets = torch.nn.ModuleList()\n",
    "        for _ in range(num_T1):\n",
    "            net = tt.practical.MLPVanilla(\n",
    "                num_nodes_shared[-1], num_nodes_indiv, out_features,\n",
    "                batch_norm, dropout,\n",
    "            )\n",
    "            self.risk_nets.append(net)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.first_layer(input)\n",
    "        out = self.shared_net(out)\n",
    "        out = [net(out) for net in self.risk_nets]\n",
    "        out = torch.stack(out, dim=1)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = x_train.shape[1]\n",
    "num_nodes_shared = [num_pathways, 32, 32]\n",
    "num_nodes_indiv = [32, 32]\n",
    "num_T1 = num_durations \n",
    "out_features = len(labtrans2.cuts)\n",
    "batch_norm = True\n",
    "dropout = 0.7\n",
    "\n",
    "net = Multivariate_survival(in_features, num_nodes_shared, num_nodes_indiv, num_T1,\n",
    "                       out_features, batch_norm, dropout, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class second_multi_task(tt.Model):\n",
    "\n",
    "    def __init__(self, net, optimizer=None, device=None, alpha=0.2, sigma=0.1, duration_index=None, loss=None):\n",
    "        self.duration_index = duration_index\n",
    "        if loss is None:\n",
    "            loss = Loss1(alpha, sigma)\n",
    "        super().__init__(net, loss, optimizer, device)\n",
    "\n",
    "    @property\n",
    "    def duration_index(self):\n",
    "        \n",
    "        return self._duration_index\n",
    "\n",
    "    @duration_index.setter\n",
    "    def duration_index(self, val):\n",
    "        self._duration_index = val\n",
    "\n",
    "    def make_dataloader(self, data, batch_size, shuffle, num_workers=0):\n",
    "        dataloader = super().make_dataloader(data, batch_size, shuffle, num_workers,\n",
    "                                             make_dataset=models.data.DeepHitDataset)\n",
    "        return dataloader\n",
    "    \n",
    "    def make_dataloader_predict(self, input, batch_size, shuffle=False, num_workers=0):\n",
    "        dataloader = super().make_dataloader(input, batch_size, shuffle, num_workers)\n",
    "        return dataloader\n",
    "\n",
    "    def predict_surv_df(self, input, batch_size=8224, eval_=True, num_workers=0):\n",
    "\n",
    "        surv = self.predict_pmf_1_cif_2(input, batch_size, True, eval_, True, num_workers)\n",
    "        return pd.DataFrame(surv, self.duration_index)\n",
    "\n",
    "    def predict_surv_2_condpmf_1(self, input, batch_size=8224, numpy=None, eval_=True,\n",
    "                     to_cpu=False, num_workers=0):\n",
    " \n",
    "        cif = self.predict_pmf_1_cif_2(input, batch_size, False, eval_, to_cpu, num_workers)\n",
    "        pmf = self.predict_pmf_1(input, batch_size, False, eval_, to_cpu, num_workers)\n",
    "        condsurv = 1. - cif/pmf\n",
    "        return tt.utils.array_or_tensor(condsurv, numpy, input)\n",
    "        \n",
    "    def predict_pmf_1_cif_2(self, input, batch_size=8224, numpy=None, eval_=True,\n",
    "                     to_cpu=False, num_workers=0):\n",
    " \n",
    "        pmf = self.predict_pmf_12(input, batch_size, False, eval_, to_cpu, num_workers)\n",
    "        cif = pmf.cumsum(1)\n",
    "        return tt.utils.array_or_tensor(cif, numpy, input) \n",
    "\n",
    "    def predict_pmf_1(self, input, batch_size=8224, numpy=None, eval_=True,\n",
    "                     to_cpu=False, num_workers=0):\n",
    " \n",
    "        pmf12 = self.predict_pmf_12(input, batch_size, False, eval_, to_cpu, num_workers)\n",
    "        pmf = pmf12.sum(1)\n",
    "        return tt.utils.array_or_tensor(pmf, numpy, input)\n",
    "    \n",
    "    def predict_pmf_12(self, input, batch_size=8224, numpy=None, eval_=True,\n",
    "                     to_cpu=False, num_workers=0):\n",
    " \n",
    "        preds = self.predict(input, batch_size, False, eval_, False, to_cpu, num_workers)\n",
    "        pmf = pad_col(preds.view(preds.size(0), -1)).softmax(1)[:, :-1]\n",
    "        pmf = pmf.view(preds.shape).transpose(0, 1).transpose(1, 2)\n",
    "        return tt.utils.array_or_tensor(pmf, numpy, input)\n",
    "\n",
    "def _reduction(loss: Tensor, reduction: str = 'mean') -> Tensor:\n",
    "    if reduction == 'none':\n",
    "        return loss\n",
    "    elif reduction == 'mean':\n",
    "        return loss.mean()\n",
    "    elif reduction == 'sum':\n",
    "        return loss.sum()\n",
    "    raise ValueError(f\"`reduction` = {reduction} is not valid. Use 'none', 'mean' or 'sum'.\")\n",
    "\n",
    "def _diff_cdf_at_time_i(pmf: Tensor, y: Tensor) -> Tensor:\n",
    "\n",
    "    n = pmf.shape[0]\n",
    "    ones = torch.ones((n, 1), device=pmf.device)\n",
    "    r = pmf.cumsum(1).matmul(y.transpose(0, 1))\n",
    "    diag_r = r.diag().view(1, -1)\n",
    "    r = ones.matmul(diag_r) - r\n",
    "    return r.transpose(0, 1)\n",
    "\n",
    "def _rank_loss_deephit(pmf: Tensor, y: Tensor, rank_mat: Tensor, sigma: float,\n",
    "                       reduction: str = 'mean') -> Tensor:\n",
    "\n",
    "    r = _diff_cdf_at_time_i(pmf, y)\n",
    "    loss = rank_mat * torch.exp(-r/sigma)\n",
    "    loss = loss.mean(1, keepdim=True)\n",
    "    return _reduction(loss, reduction)\n",
    "\n",
    "def index_from_1d(k, n):\n",
    "\n",
    "    i = k // n\n",
    "    j = k % n\n",
    "    return (i, j)\n",
    "    \n",
    "def nll_pmf_cr(phi: Tensor, idx_durations: Tensor, events: Tensor, reduction: str = 'mean',\n",
    "               epsilon: float = 1e-7) -> Tensor:\n",
    "\n",
    "    events = events.view(-1)\n",
    "    event_00 = (events == 0).float()\n",
    "    event_01 = (events == 1).float()\n",
    "    event_02 = (events == 2).float()\n",
    "    event_03 = (events == 3).float()\n",
    "    \n",
    "    idx_durations1, idx_durations2 = index_from_1d(idx_durations.view(-1), num_durations)\n",
    "    batch_size = phi.size(0)\n",
    "    sm = utils.pad_col(phi.view(batch_size, -1)).softmax(1)[:, :-1].view(phi.shape)\n",
    "    index = torch.arange(batch_size)\n",
    "    part1 = sm[index, idx_durations1, idx_durations2].relu().add(epsilon).log().mul(event_03)\n",
    "    part2 = (sm[index, idx_durations1, :].sum(1) - sm.cumsum(2)[index, idx_durations1, idx_durations2]).relu().add(epsilon).log().mul(event_02)\n",
    "    part3 = (sm[index, :, idx_durations2].sum(1) - sm.cumsum(1)[index, idx_durations1, idx_durations2]).relu().add(epsilon).log().mul(event_01)\n",
    "    part4 = (1 - sm.cumsum(2)[index, :, idx_durations2].sum(1) + sm.cumsum(1).cumsum(2)[index, idx_durations1, idx_durations2] - sm.cumsum(1)[index, idx_durations1, :].sum(1)).relu().add(epsilon).log().mul(event_00)     \n",
    "     \n",
    "    loss = - part1.add(part2).add(part3).add(part4)\n",
    "    return _reduction(loss, reduction)\n",
    "\n",
    "\n",
    "\n",
    "def rank_loss_deephit_cr(phi: Tensor, idx_durations: Tensor, events: Tensor, rank_mat: Tensor,\n",
    "                         sigma: float, reduction: str = 'mean') -> Tensor:\n",
    "\n",
    "    idx_durations = idx_durations.view(-1)\n",
    "    events = events.view(-1)\n",
    "    event_00 = (events == 0).float()\n",
    "    event_01 = (events == 1).float()\n",
    "    event_02 = (events == 2).float()\n",
    "    event_03 = (events == 3).float()\n",
    "\n",
    "    batch_size = phi.size(0)\n",
    "    pmf = utils.pad_col(phi.view(batch_size, -1)).softmax(1)[:, :-1].view(phi.shape)\n",
    "    y = torch.zeros_like(pmf)\n",
    "    y[torch.arange(batch_size), :, idx_durations] = 1.\n",
    "\n",
    "    loss = []\n",
    "    for i in range(4):\n",
    "        rank_loss_i = _rank_loss_deephit(pmf[:, i, :], y[:, i, :], rank_mat, sigma, 'none')\n",
    "        loss.append(rank_loss_i.view(-1) * (events == i).float())\n",
    "\n",
    "    if reduction == 'none':\n",
    "        return sum(loss)\n",
    "    elif reduction == 'mean':\n",
    "        return sum([lo.mean() for lo in loss])\n",
    "    elif reduction == 'sum':\n",
    "        return sum([lo.sum() for lo in loss])\n",
    "    return _reduction(loss, reduction)\n",
    "\n",
    "class _Loss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, reduction: str = 'mean') -> None:\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "class _Loss1(_Loss):\n",
    "\n",
    "    def __init__(self, alpha: float, sigma: float, reduction: str = 'mean') -> None:\n",
    "        super().__init__(reduction)\n",
    "        self.alpha = alpha\n",
    "        self.sigma = sigma\n",
    "\n",
    "    @property\n",
    "    def alpha(self) -> float:\n",
    "        return self._alpha\n",
    "\n",
    "    @alpha.setter\n",
    "    def alpha(self, alpha: float) -> None:\n",
    "        if (alpha < 0) or (alpha > 1):\n",
    "            raise ValueError(f\"Need `alpha` to be in [0, 1]. Got {alpha}.\")\n",
    "        self._alpha = alpha\n",
    "\n",
    "    @property\n",
    "    def sigma(self) -> float:\n",
    "        return self._sigma\n",
    "\n",
    "    @sigma.setter\n",
    "    def sigma(self, sigma: float) -> None:\n",
    "        if sigma <= 0:\n",
    "            raise ValueError(f\"Need `sigma` to be positive. Got {sigma}.\")\n",
    "        self._sigma = sigma\n",
    "\n",
    "class Loss1(_Loss1):\n",
    "\n",
    "    def forward(self, phi: Tensor, idx_durations: Tensor, events: Tensor, rank_mat: Tensor) -> Tensor:\n",
    "        nll =  nll_pmf_cr(phi, idx_durations, events, self.reduction)\n",
    "        return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tt.optim.AdamWR(lr=0.8, decoupled_weight_decay=0.01,\n",
    "                                    cycle_eta_multiplier=0.9)\n",
    "model = second_multi_task(net, optimizer, alpha=1,\n",
    "                   duration_index=labtrans1.cuts)\n",
    "batch_size = 128\n",
    "lrfind = model.lr_finder(x_train, T_train, batch_size, tolerance=50)\n",
    "model.optimizer.set_lr(lrfind.get_best_lr()) # The learning rates for the AdamWR optimizer were adjusted using the method proposed by Smith\n",
    "epochs = 512\n",
    "callbacks = [tt.callbacks.EarlyStoppingCycle()]\n",
    "verbose = False\n",
    "log = model.fit(x_train, T_train, batch_size, epochs, callbacks, verbose, val_data=val)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-index: 0.8325406330264106\n",
      "IBS: 0.09440673971964854\n"
     ]
    }
   ],
   "source": [
    "# Spline interpolation and evaluation of predictive performance\n",
    "index = torch.arange(T1_test.size)\n",
    "x = np.linspace(0, num_durations-1, num_durations)\n",
    "\n",
    "xnew = np.linspace(0, num_durations-1, 10000)\n",
    "ynew=[]    \n",
    "for i in range(T2_test[event1_test==1].size):  \n",
    "    spline_interp = UnivariateSpline(x, (1. - (model.predict_pmf_12(x_test)[T1_test[event1_test==1],:,index[event1_test==1]].T\n",
    "                                               /model.predict_pmf_12(x_test)[T1_test[event1_test==1],:,index[event1_test==1]].sum(1)).cumsum(0))[:,i], s=0)\n",
    "    y_spline = spline_interp(xnew)\n",
    "    ynew.append(y_spline)\n",
    "        \n",
    "ynew_array = np.stack(ynew, axis=1)\n",
    "    \n",
    "surv1 = pd.DataFrame(ynew_array, np.linspace(0, labtrans2.cuts.max(), 10000))\n",
    "    \n",
    "ev1 = EvalSurv(surv1, np.array(T2_test[event1_test==1]), np.array(event2_test)[event1_test==1], censor_surv='km')\n",
    "\n",
    "ynew=[]\n",
    "\n",
    "for i in range(T2_test[event1_test==0].size):  \n",
    "    spline_interp = UnivariateSpline(x, (1-((model.predict_pmf_12(x_test).sum(0)[:,event1_test==0]-model.predict_pmf_12(x_test).cumsum(0)[T1_test[event1_test==0],:,index[event1_test==0]].T)\n",
    "                                            /(1-model.predict_pmf_12(x_test).cumsum(0)[T1_test[event1_test==0],:,index[event1_test==0]].sum(1))).cumsum(0))[:,i], s=0)\n",
    "    y_spline = spline_interp(xnew)\n",
    "    ynew.append(y_spline)\n",
    "\n",
    "ynew_array = np.stack(ynew, axis=1)\n",
    "    \n",
    "surv2 = pd.DataFrame(ynew_array, np.linspace(0, labtrans2.cuts.max(), 10000))\n",
    "\n",
    "ev2 = EvalSurv(surv2, np.array(T2_test[event1_test==0]), np.array(event2_test)[event1_test==0], censor_surv='km')\n",
    "\n",
    "time_grid = np.linspace(T2_test.min(), T2_test.max(), 100) \n",
    "\n",
    "C_index=(ev1.concordance_td()*T2_test[event1_test==1].size + ev2.concordance_td()*T2_test[event1_test==0].size)/T2_test.size\n",
    "\n",
    "IBS=(ev1.integrated_brier_score(time_grid)*T2_test[event1_test==1].size + ev2.integrated_brier_score(time_grid)*T2_test[event1_test==0].size)/T2_test.size\n",
    "\n",
    "print(\"C-index:\", C_index)\n",
    "print(\"IBS:\", IBS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
