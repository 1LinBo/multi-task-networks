{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to the first multi-task network\n",
    "\n",
    "In this notebook we introduce the use of the first multi-task network through an example dataset (TCGA-BRCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import related packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchtuples as tt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "from pycox.models.utils import pad_col\n",
    "from pycox.preprocessing.label_transforms import LabTransDiscreteTime\n",
    "from pycox import models\n",
    "from typing import Tuple\n",
    "from torch import Tensor\n",
    "from pycox.models import utils\n",
    "from torchtuples import TupleTree\n",
    "from scipy.interpolate import UnivariateSpline\n",
    " \n",
    "import sys\n",
    "sys.path.insert(0, '/')\n",
    "from eval import EvalSurv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set some seeds to make this reproducable\n",
    "np.random.seed(123456)\n",
    "_ = torch.manual_seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X100130426</th>\n",
       "      <th>X100133144</th>\n",
       "      <th>X100134869</th>\n",
       "      <th>X10357</th>\n",
       "      <th>X10431</th>\n",
       "      <th>X136542</th>\n",
       "      <th>X155060</th>\n",
       "      <th>X26823</th>\n",
       "      <th>X280660</th>\n",
       "      <th>X317712</th>\n",
       "      <th>...</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "      <th>event2</th>\n",
       "      <th>T2</th>\n",
       "      <th>event1</th>\n",
       "      <th>T1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>4.12</td>\n",
       "      <td>3.80</td>\n",
       "      <td>5.73</td>\n",
       "      <td>8.68</td>\n",
       "      <td>0</td>\n",
       "      <td>10.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.70</td>\n",
       "      <td>8.02</td>\n",
       "      <td>10.24</td>\n",
       "      <td>11.78</td>\n",
       "      <td>10.89</td>\n",
       "      <td>10.21</td>\n",
       "      <td>0</td>\n",
       "      <td>4047</td>\n",
       "      <td>1</td>\n",
       "      <td>1808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3.36</td>\n",
       "      <td>4.20</td>\n",
       "      <td>6.14</td>\n",
       "      <td>9.14</td>\n",
       "      <td>0</td>\n",
       "      <td>9.01</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.39</td>\n",
       "      <td>7.64</td>\n",
       "      <td>9.24</td>\n",
       "      <td>12.43</td>\n",
       "      <td>10.37</td>\n",
       "      <td>8.67</td>\n",
       "      <td>0</td>\n",
       "      <td>4005</td>\n",
       "      <td>0</td>\n",
       "      <td>4005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.93</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.35</td>\n",
       "      <td>7.28</td>\n",
       "      <td>10.41</td>\n",
       "      <td>0</td>\n",
       "      <td>9.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.59</td>\n",
       "      <td>8.38</td>\n",
       "      <td>9.06</td>\n",
       "      <td>12.41</td>\n",
       "      <td>9.88</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1474</td>\n",
       "      <td>0</td>\n",
       "      <td>1474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3.59</td>\n",
       "      <td>7.18</td>\n",
       "      <td>9.76</td>\n",
       "      <td>0</td>\n",
       "      <td>9.11</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.76</td>\n",
       "      <td>7.46</td>\n",
       "      <td>9.25</td>\n",
       "      <td>12.47</td>\n",
       "      <td>9.61</td>\n",
       "      <td>9.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1448</td>\n",
       "      <td>0</td>\n",
       "      <td>1448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.97</td>\n",
       "      <td>3.95</td>\n",
       "      <td>6.41</td>\n",
       "      <td>9.58</td>\n",
       "      <td>0</td>\n",
       "      <td>8.03</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.04</td>\n",
       "      <td>3.91</td>\n",
       "      <td>9.60</td>\n",
       "      <td>11.98</td>\n",
       "      <td>9.70</td>\n",
       "      <td>9.79</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "      <td>0</td>\n",
       "      <td>348</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 20535 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   X100130426  X100133144  X100134869  X10357  X10431  X136542  X155060  \\\n",
       "0        0.00        4.12        3.80    5.73    8.68        0    10.21   \n",
       "1        0.00        3.36        4.20    6.14    9.14        0     9.01   \n",
       "2        0.93        3.66        3.35    7.28   10.41        0     9.21   \n",
       "3        0.00        3.71        3.59    7.18    9.76        0     9.11   \n",
       "4        0.00        2.97        3.95    6.41    9.58        0     8.03   \n",
       "\n",
       "   X26823  X280660  X317712  ...   ZXDC  ZYG11A  ZYG11B    ZYX  ZZEF1   ZZZ3  \\\n",
       "0    0.00     0.00      0.0  ...  10.70    8.02   10.24  11.78  10.89  10.21   \n",
       "1    1.06     0.63      0.0  ...  10.39    7.64    9.24  12.43  10.37   8.67   \n",
       "2    0.00     0.00      0.0  ...   9.59    8.38    9.06  12.41   9.88   9.00   \n",
       "3    0.50     0.00      0.0  ...   9.76    7.46    9.25  12.47   9.61   9.46   \n",
       "4    0.51     0.00      0.0  ...  10.04    3.91    9.60  11.98   9.70   9.79   \n",
       "\n",
       "   event2    T2  event1    T1  \n",
       "0       0  4047       1  1808  \n",
       "1       0  4005       0  4005  \n",
       "2       0  1474       0  1474  \n",
       "3       0  1448       0  1448  \n",
       "4       0   348       0   348  \n",
       "\n",
       "[5 rows x 20535 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "file_path = 'BRCA.txt'\n",
    "\n",
    "df_train = pd.read_csv(file_path, sep='\\t', header=0)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['X100130426',\n",
       " 'X100133144',\n",
       " 'X100134869',\n",
       " 'X10357',\n",
       " 'X10431',\n",
       " 'X136542',\n",
       " 'X155060',\n",
       " 'X26823',\n",
       " 'X280660',\n",
       " 'X317712',\n",
       " 'X340602',\n",
       " 'X388795',\n",
       " 'X390284',\n",
       " 'X391343',\n",
       " 'X391714',\n",
       " 'X404770',\n",
       " 'X441362',\n",
       " 'X442388',\n",
       " 'X553137',\n",
       " 'X57714',\n",
       " 'X645851',\n",
       " 'X652919',\n",
       " 'X653553',\n",
       " 'X728045',\n",
       " 'X728603',\n",
       " 'X728788',\n",
       " 'X729884',\n",
       " 'X8225',\n",
       " 'X90288',\n",
       " 'A1BG',\n",
       " 'A1CF',\n",
       " 'A2BP1',\n",
       " 'A2LD1',\n",
       " 'A2M',\n",
       " 'A2ML1',\n",
       " 'A4GALT',\n",
       " 'A4GNT',\n",
       " 'AAA1',\n",
       " 'AAAS',\n",
       " 'AACS',\n",
       " 'AACSL',\n",
       " 'AADAC',\n",
       " 'AADACL2',\n",
       " 'AADACL3',\n",
       " 'AADACL4',\n",
       " 'AADAT',\n",
       " 'AAGAB',\n",
       " 'AAK1',\n",
       " 'AAMP',\n",
       " 'AANAT',\n",
       " 'AARS',\n",
       " 'AARS2',\n",
       " 'AARSD1',\n",
       " 'AASDH',\n",
       " 'AASDHPPT',\n",
       " 'AASS',\n",
       " 'AATF',\n",
       " 'AATK',\n",
       " 'ABAT',\n",
       " 'ABCA10',\n",
       " 'ABCA1',\n",
       " 'ABCA11P',\n",
       " 'ABCA12',\n",
       " 'ABCA13',\n",
       " 'ABCA17P',\n",
       " 'ABCA2',\n",
       " 'ABCA3',\n",
       " 'ABCA4',\n",
       " 'ABCA5',\n",
       " 'ABCA6',\n",
       " 'ABCA7',\n",
       " 'ABCA8',\n",
       " 'ABCA9',\n",
       " 'ABCB10',\n",
       " 'ABCB11',\n",
       " 'ABCB1',\n",
       " 'ABCB4',\n",
       " 'ABCB5',\n",
       " 'ABCB6',\n",
       " 'ABCB7',\n",
       " 'ABCB8',\n",
       " 'ABCB9',\n",
       " 'ABCC10',\n",
       " 'ABCC11',\n",
       " 'ABCC12',\n",
       " 'ABCC13',\n",
       " 'ABCC1',\n",
       " 'ABCC2',\n",
       " 'ABCC3',\n",
       " 'ABCC4',\n",
       " 'ABCC5',\n",
       " 'ABCC6',\n",
       " 'ABCC6P1',\n",
       " 'ABCC6P2',\n",
       " 'ABCC8',\n",
       " 'ABCC9',\n",
       " 'ABCD1',\n",
       " 'ABCD2',\n",
       " 'ABCD3',\n",
       " 'ABCD4',\n",
       " 'ABCE1',\n",
       " 'ABCF1',\n",
       " 'ABCF2',\n",
       " 'ABCF3',\n",
       " 'ABCG1',\n",
       " 'ABCG2',\n",
       " 'ABCG4',\n",
       " 'ABCG5',\n",
       " 'ABCG8',\n",
       " 'ABHD10',\n",
       " 'ABHD11',\n",
       " 'ABHD12',\n",
       " 'ABHD12B',\n",
       " 'ABHD13',\n",
       " 'ABHD14A',\n",
       " 'ABHD14B',\n",
       " 'ABHD15',\n",
       " 'ABHD1',\n",
       " 'ABHD2',\n",
       " 'ABHD3',\n",
       " 'ABHD4',\n",
       " 'ABHD5',\n",
       " 'ABHD6',\n",
       " 'ABHD8',\n",
       " 'ABI1',\n",
       " 'ABI2',\n",
       " 'ABI3',\n",
       " 'ABI3BP',\n",
       " 'ABL1',\n",
       " 'ABL2',\n",
       " 'ABLIM1',\n",
       " 'ABLIM2',\n",
       " 'ABLIM3',\n",
       " 'ABO',\n",
       " 'ABP1',\n",
       " 'ABR',\n",
       " 'ABRA',\n",
       " 'ABT1',\n",
       " 'ABTB1',\n",
       " 'ABTB2',\n",
       " 'ACAA1',\n",
       " 'ACAA2',\n",
       " 'ACACA',\n",
       " 'ACACB',\n",
       " 'ACAD10',\n",
       " 'ACAD11',\n",
       " 'ACAD8',\n",
       " 'ACAD9',\n",
       " 'ACADL',\n",
       " 'ACADM',\n",
       " 'ACADS',\n",
       " 'ACADSB',\n",
       " 'ACADVL',\n",
       " 'ACAN',\n",
       " 'ACAP1',\n",
       " 'ACAP2',\n",
       " 'ACAP3',\n",
       " 'ACAT1',\n",
       " 'ACAT2',\n",
       " 'ACBD3',\n",
       " 'ACBD4',\n",
       " 'ACBD5',\n",
       " 'ACBD6',\n",
       " 'ACBD7',\n",
       " 'ACCN1',\n",
       " 'ACCN2',\n",
       " 'ACCN3',\n",
       " 'ACCN4',\n",
       " 'ACCN5',\n",
       " 'ACCS',\n",
       " 'ACCSL',\n",
       " 'ACD',\n",
       " 'ACE',\n",
       " 'ACE2',\n",
       " 'ACER1',\n",
       " 'ACER2',\n",
       " 'ACER3',\n",
       " 'ACHE',\n",
       " 'ACIN1',\n",
       " 'ACLY',\n",
       " 'ACMSD',\n",
       " 'ACN9',\n",
       " 'ACO1',\n",
       " 'ACO2',\n",
       " 'ACOT11',\n",
       " 'ACOT12',\n",
       " 'ACOT13',\n",
       " 'ACOT1',\n",
       " 'ACOT2',\n",
       " 'ACOT4',\n",
       " 'ACOT6',\n",
       " 'ACOT7',\n",
       " 'ACOT8',\n",
       " 'ACOT9',\n",
       " 'ACOX1',\n",
       " 'ACOX2',\n",
       " 'ACOX3',\n",
       " 'ACOXL',\n",
       " 'ACP1',\n",
       " 'ACP2',\n",
       " 'ACP5',\n",
       " 'ACP6',\n",
       " 'ACPL2',\n",
       " 'ACPP',\n",
       " 'ACPT',\n",
       " 'ACR',\n",
       " 'ACRBP',\n",
       " 'ACRC',\n",
       " 'ACRV1',\n",
       " 'ACSBG1',\n",
       " 'ACSBG2',\n",
       " 'ACSF2',\n",
       " 'ACSF3',\n",
       " 'ACSL1',\n",
       " 'ACSL3',\n",
       " 'ACSL4',\n",
       " 'ACSL5',\n",
       " 'ACSL6',\n",
       " 'ACSM1',\n",
       " 'ACSM2A',\n",
       " 'ACSM2B',\n",
       " 'ACSM3',\n",
       " 'ACSM4',\n",
       " 'ACSM5',\n",
       " 'ACSS1',\n",
       " 'ACSS2',\n",
       " 'ACSS3',\n",
       " 'ACTA1',\n",
       " 'ACTA2',\n",
       " 'ACTB',\n",
       " 'ACTBL2',\n",
       " 'ACTC1',\n",
       " 'ACTG1',\n",
       " 'ACTG2',\n",
       " 'ACTL6A',\n",
       " 'ACTL6B',\n",
       " 'ACTL7A',\n",
       " 'ACTL7B',\n",
       " 'ACTL8',\n",
       " 'ACTL9',\n",
       " 'ACTN1',\n",
       " 'ACTN2',\n",
       " 'ACTN3',\n",
       " 'ACTN4',\n",
       " 'ACTR10',\n",
       " 'ACTR1A',\n",
       " 'ACTR1B',\n",
       " 'ACTR2',\n",
       " 'ACTR3',\n",
       " 'ACTR3B',\n",
       " 'ACTR3C',\n",
       " 'ACTR5',\n",
       " 'ACTR6',\n",
       " 'ACTR8',\n",
       " 'ACTRT1',\n",
       " 'ACTRT2',\n",
       " 'ACVR1',\n",
       " 'ACVR1B',\n",
       " 'ACVR1C',\n",
       " 'ACVR2A',\n",
       " 'ACVR2B',\n",
       " 'ACVRL1',\n",
       " 'ACY1',\n",
       " 'ACY3',\n",
       " 'ACYP1',\n",
       " 'ACYP2',\n",
       " 'ADA',\n",
       " 'ADAD1',\n",
       " 'ADAD2',\n",
       " 'ADAL',\n",
       " 'ADAM10',\n",
       " 'ADAM11',\n",
       " 'ADAM12',\n",
       " 'ADAM15',\n",
       " 'ADAM17',\n",
       " 'ADAM18',\n",
       " 'ADAM19',\n",
       " 'ADAM20',\n",
       " 'ADAM21',\n",
       " 'ADAM21P1',\n",
       " 'ADAM2',\n",
       " 'ADAM22',\n",
       " 'ADAM23',\n",
       " 'ADAM28',\n",
       " 'ADAM29',\n",
       " 'ADAM30',\n",
       " 'ADAM32',\n",
       " 'ADAM33',\n",
       " 'ADAM3A',\n",
       " 'ADAM5P',\n",
       " 'ADAM6',\n",
       " 'ADAM7',\n",
       " 'ADAM8',\n",
       " 'ADAM9',\n",
       " 'ADAMDEC1',\n",
       " 'ADAMTS10',\n",
       " 'ADAMTS12',\n",
       " 'ADAMTS13',\n",
       " 'ADAMTS14',\n",
       " 'ADAMTS15',\n",
       " 'ADAMTS16',\n",
       " 'ADAMTS17',\n",
       " 'ADAMTS18',\n",
       " 'ADAMTS19',\n",
       " 'ADAMTS1',\n",
       " 'ADAMTS20',\n",
       " 'ADAMTS2',\n",
       " 'ADAMTS3',\n",
       " 'ADAMTS4',\n",
       " 'ADAMTS5',\n",
       " 'ADAMTS6',\n",
       " 'ADAMTS7',\n",
       " 'ADAMTS8',\n",
       " 'ADAMTS9',\n",
       " 'ADAMTSL1',\n",
       " 'ADAMTSL2',\n",
       " 'ADAMTSL3',\n",
       " 'ADAMTSL4',\n",
       " 'ADAMTSL5',\n",
       " 'ADAP1',\n",
       " 'ADAP2',\n",
       " 'ADAR',\n",
       " 'ADARB1',\n",
       " 'ADARB2',\n",
       " 'ADAT1',\n",
       " 'ADAT2',\n",
       " 'ADAT3',\n",
       " 'ADC',\n",
       " 'ADCK1',\n",
       " 'ADCK2',\n",
       " 'ADCK4',\n",
       " 'ADCK5',\n",
       " 'ADCY10',\n",
       " 'ADCY1',\n",
       " 'ADCY2',\n",
       " 'ADCY3',\n",
       " 'ADCY4',\n",
       " 'ADCY5',\n",
       " 'ADCY6',\n",
       " 'ADCY7',\n",
       " 'ADCY8',\n",
       " 'ADCY9',\n",
       " 'ADCYAP1',\n",
       " 'ADCYAP1R1',\n",
       " 'ADD1',\n",
       " 'ADD2',\n",
       " 'ADD3',\n",
       " 'ADH1A',\n",
       " 'ADH1B',\n",
       " 'ADH1C',\n",
       " 'ADH4',\n",
       " 'ADH5',\n",
       " 'ADH6',\n",
       " 'ADH7',\n",
       " 'ADHFE1',\n",
       " 'ADI1',\n",
       " 'ADIG',\n",
       " 'ADIPOQ',\n",
       " 'ADIPOR1',\n",
       " 'ADIPOR2',\n",
       " 'ADK',\n",
       " 'ADM',\n",
       " 'ADM2',\n",
       " 'ADNP2',\n",
       " 'ADNP',\n",
       " 'ADO',\n",
       " 'ADORA1',\n",
       " 'ADORA2A',\n",
       " 'ADORA2B',\n",
       " 'ADORA3',\n",
       " 'ADPGK',\n",
       " 'ADPRH',\n",
       " 'ADPRHL1',\n",
       " 'ADPRHL2',\n",
       " 'ADRA1A',\n",
       " 'ADRA1B',\n",
       " 'ADRA1D',\n",
       " 'ADRA2A',\n",
       " 'ADRA2B',\n",
       " 'ADRA2C',\n",
       " 'ADRB1',\n",
       " 'ADRB2',\n",
       " 'ADRB3',\n",
       " 'ADRBK1',\n",
       " 'ADRBK2',\n",
       " 'ADRM1',\n",
       " 'ADSL',\n",
       " 'ADSS',\n",
       " 'ADSSL1',\n",
       " 'AEBP1',\n",
       " 'AEBP2',\n",
       " 'AEN',\n",
       " 'AES',\n",
       " 'AFAP1',\n",
       " 'AFAP1L1',\n",
       " 'AFAP1L2',\n",
       " 'AFARP1',\n",
       " 'AFF1',\n",
       " 'AFF2',\n",
       " 'AFF3',\n",
       " 'AFF4',\n",
       " 'AFG3L1',\n",
       " 'AFG3L2',\n",
       " 'AFM',\n",
       " 'AFMID',\n",
       " 'AFP',\n",
       " 'AFTPH',\n",
       " 'AG2',\n",
       " 'AGA',\n",
       " 'AGAP11',\n",
       " 'AGAP1',\n",
       " 'AGAP2',\n",
       " 'AGAP3',\n",
       " 'AGAP4',\n",
       " 'AGAP5',\n",
       " 'AGAP6',\n",
       " 'AGAP7',\n",
       " 'AGAP8',\n",
       " 'AGBL1',\n",
       " 'AGBL2',\n",
       " 'AGBL3',\n",
       " 'AGBL4',\n",
       " 'AGBL5',\n",
       " 'AGER',\n",
       " 'AGFG1',\n",
       " 'AGFG2',\n",
       " 'AGGF1',\n",
       " 'AGK',\n",
       " 'AGL',\n",
       " 'AGMAT',\n",
       " 'AGPAT1',\n",
       " 'AGPAT2',\n",
       " 'AGPAT3',\n",
       " 'AGPAT4',\n",
       " 'AGPAT5',\n",
       " 'AGPAT6',\n",
       " 'AGPAT9',\n",
       " 'AGPHD1',\n",
       " 'AGPS',\n",
       " 'AGR2',\n",
       " 'AGR3',\n",
       " 'AGRN',\n",
       " 'AGRP',\n",
       " 'AGT',\n",
       " 'AGTPBP1',\n",
       " 'AGTR1',\n",
       " 'AGTR2',\n",
       " 'AGTRAP',\n",
       " 'AGXT',\n",
       " 'AGXT2',\n",
       " 'AGXT2L1',\n",
       " 'AGXT2L2',\n",
       " 'AHCTF1',\n",
       " 'AHCY',\n",
       " 'AHCYL1',\n",
       " 'AHCYL2',\n",
       " 'AHDC1',\n",
       " 'AHI1',\n",
       " 'AHNAK2',\n",
       " 'AHNAK',\n",
       " 'AHR',\n",
       " 'AHRR',\n",
       " 'AHSA1',\n",
       " 'AHSA2',\n",
       " 'AHSG',\n",
       " 'AHSP',\n",
       " 'AICDA',\n",
       " 'AIDA',\n",
       " 'AIF1',\n",
       " 'AIF1L',\n",
       " 'AIFM1',\n",
       " 'AIFM2',\n",
       " 'AIFM3',\n",
       " 'AIG1',\n",
       " 'AIM1',\n",
       " 'AIM1L',\n",
       " 'AIM2',\n",
       " 'AIMP1',\n",
       " 'AIMP2',\n",
       " 'AIP',\n",
       " 'AIPL1',\n",
       " 'AIRE',\n",
       " 'AJAP1',\n",
       " 'AK1',\n",
       " 'AK2',\n",
       " 'AK3',\n",
       " 'AK3L1',\n",
       " 'AK5',\n",
       " 'AK7',\n",
       " 'AKAP10',\n",
       " 'AKAP11',\n",
       " 'AKAP12',\n",
       " 'AKAP13',\n",
       " 'AKAP14',\n",
       " 'AKAP1',\n",
       " 'AKAP2',\n",
       " 'AKAP3',\n",
       " 'AKAP4',\n",
       " 'AKAP5',\n",
       " 'AKAP6',\n",
       " 'AKAP7',\n",
       " 'AKAP8',\n",
       " 'AKAP8L',\n",
       " 'AKAP9',\n",
       " 'AKD1',\n",
       " 'AKIRIN1',\n",
       " 'AKIRIN2',\n",
       " 'AKNA',\n",
       " 'AKNAD1',\n",
       " 'AKR1A1',\n",
       " 'AKR1B10',\n",
       " 'AKR1B1',\n",
       " 'AKR1B15',\n",
       " 'AKR1C1',\n",
       " 'AKR1C2',\n",
       " 'AKR1C3',\n",
       " 'AKR1C4',\n",
       " 'AKR1CL1',\n",
       " 'AKR1D1',\n",
       " 'AKR1E2',\n",
       " 'AKR7A2',\n",
       " 'AKR7A3',\n",
       " 'AKR7L',\n",
       " 'AKT1',\n",
       " 'AKT1S1',\n",
       " 'AKT2',\n",
       " 'AKT3',\n",
       " 'AKTIP',\n",
       " 'ALAD',\n",
       " 'ALAS1',\n",
       " 'ALAS2',\n",
       " 'ALB',\n",
       " 'ALCAM',\n",
       " 'ALDH16A1',\n",
       " 'ALDH18A1',\n",
       " 'ALDH1A1',\n",
       " 'ALDH1A2',\n",
       " 'ALDH1A3',\n",
       " 'ALDH1B1',\n",
       " 'ALDH1L1',\n",
       " 'ALDH1L2',\n",
       " 'ALDH2',\n",
       " 'ALDH3A1',\n",
       " 'ALDH3A2',\n",
       " 'ALDH3B1',\n",
       " 'ALDH3B2',\n",
       " 'ALDH4A1',\n",
       " 'ALDH5A1',\n",
       " 'ALDH6A1',\n",
       " 'ALDH7A1',\n",
       " 'ALDH8A1',\n",
       " 'ALDH9A1',\n",
       " 'ALDOA',\n",
       " 'ALDOB',\n",
       " 'ALDOC',\n",
       " 'ALG10',\n",
       " 'ALG10B',\n",
       " 'ALG11',\n",
       " 'ALG12',\n",
       " 'ALG13',\n",
       " 'ALG14',\n",
       " 'ALG1',\n",
       " 'ALG1L',\n",
       " 'ALG1L2',\n",
       " 'ALG2',\n",
       " 'ALG3',\n",
       " 'ALG5',\n",
       " 'ALG6',\n",
       " 'ALG8',\n",
       " 'ALG9',\n",
       " 'ALK',\n",
       " 'ALKBH1',\n",
       " 'ALKBH2',\n",
       " 'ALKBH3',\n",
       " 'ALKBH4',\n",
       " 'ALKBH5',\n",
       " 'ALKBH6',\n",
       " 'ALKBH7',\n",
       " 'ALKBH8',\n",
       " 'ALLC',\n",
       " 'ALMS1',\n",
       " 'ALMS1P',\n",
       " 'ALOX12',\n",
       " 'ALOX12B',\n",
       " 'ALOX12P2',\n",
       " 'ALOX15',\n",
       " 'ALOX15B',\n",
       " 'ALOX5',\n",
       " 'ALOX5AP',\n",
       " 'ALOXE3',\n",
       " 'ALPI',\n",
       " 'ALPK1',\n",
       " 'ALPK2',\n",
       " 'ALPK3',\n",
       " 'ALPL',\n",
       " 'ALPP',\n",
       " 'ALPPL2',\n",
       " 'ALS2',\n",
       " 'ALS2CL',\n",
       " 'ALS2CR11',\n",
       " 'ALS2CR12',\n",
       " 'ALS2CR4',\n",
       " 'ALS2CR8',\n",
       " 'ALX1',\n",
       " 'ALX3',\n",
       " 'ALX4',\n",
       " 'AMAC1',\n",
       " 'AMAC1L2',\n",
       " 'AMAC1L3',\n",
       " 'AMACR',\n",
       " 'AMBN',\n",
       " 'AMBP',\n",
       " 'AMBRA1',\n",
       " 'AMD1',\n",
       " 'AMDHD1',\n",
       " 'AMDHD2',\n",
       " 'AMELX',\n",
       " 'AMELY',\n",
       " 'AMFR',\n",
       " 'AMH',\n",
       " 'AMHR2',\n",
       " 'AMICA1',\n",
       " 'AMIGO1',\n",
       " 'AMIGO2',\n",
       " 'AMIGO3',\n",
       " 'AMMECR1',\n",
       " 'AMMECR1L',\n",
       " 'AMN1',\n",
       " 'AMN',\n",
       " 'AMOT',\n",
       " 'AMOTL1',\n",
       " 'AMOTL2',\n",
       " 'AMPD1',\n",
       " 'AMPD2',\n",
       " 'AMPD3',\n",
       " 'AMPH',\n",
       " 'AMT',\n",
       " 'AMTN',\n",
       " 'AMY1A',\n",
       " 'AMY2A',\n",
       " 'AMY2B',\n",
       " 'AMZ1',\n",
       " 'AMZ2',\n",
       " 'AMZ2P1',\n",
       " 'ANAPC10',\n",
       " 'ANAPC11',\n",
       " 'ANAPC13',\n",
       " 'ANAPC16',\n",
       " 'ANAPC1',\n",
       " 'ANAPC2',\n",
       " 'ANAPC4',\n",
       " 'ANAPC5',\n",
       " 'ANAPC7',\n",
       " 'ANG',\n",
       " 'ANGEL1',\n",
       " 'ANGEL2',\n",
       " 'ANGPT1',\n",
       " 'ANGPT2',\n",
       " 'ANGPT4',\n",
       " 'ANGPTL1',\n",
       " 'ANGPTL2',\n",
       " 'ANGPTL3',\n",
       " 'ANGPTL4',\n",
       " 'ANGPTL5',\n",
       " 'ANGPTL6',\n",
       " 'ANGPTL7',\n",
       " 'ANK1',\n",
       " 'ANK2',\n",
       " 'ANK3',\n",
       " 'ANKAR',\n",
       " 'ANKDD1A',\n",
       " 'ANKFN1',\n",
       " 'ANKFY1',\n",
       " 'ANKH',\n",
       " 'ANKHD1',\n",
       " 'ANKHD1.EIF4EBP3',\n",
       " 'ANKIB1',\n",
       " 'ANKK1',\n",
       " 'ANKLE1',\n",
       " 'ANKLE2',\n",
       " 'ANKMY1',\n",
       " 'ANKMY2',\n",
       " 'ANKRA2',\n",
       " 'ANKRD10',\n",
       " 'ANKRD11',\n",
       " 'ANKRD12',\n",
       " 'ANKRD1',\n",
       " 'ANKRD13A',\n",
       " 'ANKRD13B',\n",
       " 'ANKRD13C',\n",
       " 'ANKRD13D',\n",
       " 'ANKRD16',\n",
       " 'ANKRD17',\n",
       " 'ANKRD19',\n",
       " 'ANKRD20A3',\n",
       " 'ANKRD20A4',\n",
       " 'ANKRD20B',\n",
       " 'ANKRD22',\n",
       " 'ANKRD2',\n",
       " 'ANKRD23',\n",
       " 'ANKRD24',\n",
       " 'ANKRD26',\n",
       " 'ANKRD26P1',\n",
       " 'ANKRD27',\n",
       " 'ANKRD28',\n",
       " 'ANKRD29',\n",
       " 'ANKRD30A',\n",
       " 'ANKRD30B',\n",
       " 'ANKRD31',\n",
       " 'ANKRD32',\n",
       " 'ANKRD33',\n",
       " 'ANKRD34A',\n",
       " 'ANKRD34B',\n",
       " 'ANKRD34C',\n",
       " 'ANKRD35',\n",
       " 'ANKRD36',\n",
       " 'ANKRD36B',\n",
       " 'ANKRD36BP1',\n",
       " 'ANKRD37',\n",
       " 'ANKRD39',\n",
       " 'ANKRD40',\n",
       " 'ANKRD42',\n",
       " 'ANKRD43',\n",
       " 'ANKRD44',\n",
       " 'ANKRD45',\n",
       " 'ANKRD46',\n",
       " 'ANKRD49',\n",
       " 'ANKRD50',\n",
       " 'ANKRD52',\n",
       " 'ANKRD53',\n",
       " 'ANKRD54',\n",
       " 'ANKRD55',\n",
       " 'ANKRD56',\n",
       " 'ANKRD5',\n",
       " 'ANKRD57',\n",
       " 'ANKRD58',\n",
       " 'ANKRD6',\n",
       " 'ANKRD7',\n",
       " 'ANKRD9',\n",
       " 'ANKS1A',\n",
       " 'ANKS1B',\n",
       " 'ANKS3',\n",
       " 'ANKS4B',\n",
       " 'ANKS6',\n",
       " 'ANKZF1',\n",
       " 'ANLN',\n",
       " 'ANO10',\n",
       " 'ANO1',\n",
       " 'ANO2',\n",
       " 'ANO3',\n",
       " 'ANO4',\n",
       " 'ANO5',\n",
       " 'ANO6',\n",
       " 'ANO7',\n",
       " 'ANO8',\n",
       " 'ANO9',\n",
       " 'ANP32A',\n",
       " 'ANP32B',\n",
       " 'ANP32C',\n",
       " 'ANP32D',\n",
       " 'ANP32E',\n",
       " 'ANPEP',\n",
       " 'ANTXR1',\n",
       " 'ANTXR2',\n",
       " 'ANTXRL',\n",
       " 'ANUBL1',\n",
       " 'ANXA10',\n",
       " 'ANXA11',\n",
       " 'ANXA1',\n",
       " 'ANXA13',\n",
       " 'ANXA2',\n",
       " 'ANXA2P1',\n",
       " 'ANXA2P2',\n",
       " 'ANXA2P3',\n",
       " 'ANXA3',\n",
       " 'ANXA4',\n",
       " 'ANXA5',\n",
       " 'ANXA6',\n",
       " 'ANXA7',\n",
       " 'ANXA8',\n",
       " 'ANXA8L1',\n",
       " 'ANXA8L2',\n",
       " 'ANXA9',\n",
       " 'AOAH',\n",
       " 'AOC2',\n",
       " 'AOC3',\n",
       " 'AOX1',\n",
       " 'AOX2P',\n",
       " 'AP1AR',\n",
       " 'AP1B1',\n",
       " 'AP1G1',\n",
       " 'AP1G2',\n",
       " 'AP1M1',\n",
       " 'AP1M2',\n",
       " 'AP1S1',\n",
       " 'AP1S2',\n",
       " 'AP1S3',\n",
       " 'AP2A1',\n",
       " 'AP2A2',\n",
       " 'AP2B1',\n",
       " 'AP2M1',\n",
       " 'AP2S1',\n",
       " 'AP3B1',\n",
       " 'AP3B2',\n",
       " 'AP3D1',\n",
       " 'AP3M1',\n",
       " 'AP3M2',\n",
       " 'AP3S1',\n",
       " 'AP3S2',\n",
       " 'AP4B1',\n",
       " 'AP4E1',\n",
       " 'AP4M1',\n",
       " 'AP4S1',\n",
       " 'APAF1',\n",
       " 'APBA1',\n",
       " 'APBA2',\n",
       " 'APBA3',\n",
       " 'APBB1',\n",
       " 'APBB1IP',\n",
       " 'APBB2',\n",
       " 'APBB3',\n",
       " 'APC2',\n",
       " 'APC',\n",
       " 'APCDD1',\n",
       " 'APCDD1L',\n",
       " 'APCS',\n",
       " 'APEH',\n",
       " 'APEX1',\n",
       " 'APEX2',\n",
       " 'APH1A',\n",
       " 'APH1B',\n",
       " 'API5',\n",
       " 'APIP',\n",
       " 'APITD1',\n",
       " 'APLF',\n",
       " 'APLN',\n",
       " 'APLNR',\n",
       " 'APLP1',\n",
       " 'APLP2',\n",
       " 'APOA1',\n",
       " 'APOA1BP',\n",
       " 'APOA2',\n",
       " 'APOA4',\n",
       " 'APOA5',\n",
       " 'APOB',\n",
       " 'APOB48R',\n",
       " 'APOBEC1',\n",
       " 'APOBEC2',\n",
       " 'APOBEC3A',\n",
       " 'APOBEC3B',\n",
       " 'APOBEC3C',\n",
       " 'APOBEC3D',\n",
       " 'APOBEC3F',\n",
       " 'APOBEC3G',\n",
       " 'APOBEC3H',\n",
       " 'APOBEC4',\n",
       " 'APOC1',\n",
       " 'APOC1P1',\n",
       " 'APOC2',\n",
       " 'APOC3',\n",
       " 'APOC4',\n",
       " 'APOD',\n",
       " 'APOE',\n",
       " 'APOF',\n",
       " 'APOH',\n",
       " 'APOL1',\n",
       " 'APOL2',\n",
       " 'APOL3',\n",
       " 'APOL4',\n",
       " 'APOL5',\n",
       " 'APOL6',\n",
       " 'APOLD1',\n",
       " 'APOM',\n",
       " 'APOO',\n",
       " 'APOOL',\n",
       " 'APP',\n",
       " 'APPBP2',\n",
       " 'APPL1',\n",
       " 'APPL2',\n",
       " 'APRT',\n",
       " 'APTX',\n",
       " 'AQP10',\n",
       " 'AQP11',\n",
       " 'AQP12A',\n",
       " 'AQP12B',\n",
       " 'AQP1',\n",
       " 'AQP2',\n",
       " 'AQP3',\n",
       " 'AQP4',\n",
       " 'AQP5',\n",
       " 'AQP6',\n",
       " 'AQP7',\n",
       " 'AQP7P1',\n",
       " 'AQP7P3',\n",
       " 'AQP8',\n",
       " 'AQP9',\n",
       " 'AQPEP',\n",
       " 'AQR',\n",
       " 'AR',\n",
       " 'ARAF',\n",
       " 'ARAP1',\n",
       " 'ARAP2',\n",
       " 'ARAP3',\n",
       " 'ARC',\n",
       " 'ARCN1',\n",
       " 'AREG',\n",
       " 'ARF1',\n",
       " 'ARF3',\n",
       " 'ARF4',\n",
       " 'ARF5',\n",
       " 'ARF6',\n",
       " 'ARFGAP1',\n",
       " 'ARFGAP2',\n",
       " 'ARFGAP3',\n",
       " 'ARFGEF1',\n",
       " 'ARFGEF2',\n",
       " 'ARFIP1',\n",
       " 'ARFIP2',\n",
       " 'ARFRP1',\n",
       " 'ARG1',\n",
       " 'ARG2',\n",
       " 'ARGFX',\n",
       " 'ARGFXP2',\n",
       " 'ARGLU1',\n",
       " 'ARHGAP10',\n",
       " 'ARHGAP11A',\n",
       " 'ARHGAP11B',\n",
       " 'ARHGAP12',\n",
       " 'ARHGAP1',\n",
       " 'ARHGAP15',\n",
       " 'ARHGAP17',\n",
       " 'ARHGAP18',\n",
       " 'ARHGAP19',\n",
       " 'ARHGAP20',\n",
       " 'ARHGAP21',\n",
       " 'ARHGAP22',\n",
       " 'ARHGAP23',\n",
       " 'ARHGAP24',\n",
       " 'ARHGAP25',\n",
       " 'ARHGAP26',\n",
       " 'ARHGAP27',\n",
       " 'ARHGAP28',\n",
       " 'ARHGAP29',\n",
       " 'ARHGAP30',\n",
       " 'ARHGAP31',\n",
       " 'ARHGAP32',\n",
       " 'ARHGAP33',\n",
       " 'ARHGAP36',\n",
       " 'ARHGAP39',\n",
       " 'ARHGAP42',\n",
       " 'ARHGAP4',\n",
       " 'ARHGAP5',\n",
       " 'ARHGAP6',\n",
       " 'ARHGAP8',\n",
       " 'ARHGAP9',\n",
       " 'ARHGDIA',\n",
       " 'ARHGDIB',\n",
       " 'ARHGDIG',\n",
       " 'ARHGEF10',\n",
       " 'ARHGEF10L',\n",
       " 'ARHGEF11',\n",
       " 'ARHGEF12',\n",
       " 'ARHGEF15',\n",
       " 'ARHGEF16',\n",
       " 'ARHGEF17',\n",
       " 'ARHGEF18',\n",
       " 'ARHGEF19',\n",
       " 'ARHGEF1',\n",
       " 'ARHGEF2',\n",
       " 'ARHGEF33',\n",
       " 'ARHGEF3',\n",
       " 'ARHGEF35',\n",
       " 'ARHGEF37',\n",
       " 'ARHGEF38',\n",
       " 'ARHGEF4',\n",
       " 'ARHGEF5',\n",
       " 'ARHGEF6',\n",
       " 'ARHGEF7',\n",
       " 'ARHGEF9',\n",
       " 'ARID1A',\n",
       " 'ARID1B',\n",
       " 'ARID2',\n",
       " 'ARID3A',\n",
       " 'ARID3B',\n",
       " 'ARID3C',\n",
       " 'ARID4A',\n",
       " 'ARID4B',\n",
       " 'ARID5A',\n",
       " 'ARID5B',\n",
       " 'ARIH1',\n",
       " 'ARIH2',\n",
       " 'ARL10',\n",
       " 'ARL11',\n",
       " 'ARL13A',\n",
       " 'ARL13B',\n",
       " 'ARL1',\n",
       " 'ARL14',\n",
       " 'ARL15',\n",
       " 'ARL16',\n",
       " 'ARL17A',\n",
       " ...]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View all gene names\n",
    "xx = df_train.drop(columns=['event2','T2','event1','T1'])\n",
    "xx.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X100130426</th>\n",
       "      <th>X100133144</th>\n",
       "      <th>X100134869</th>\n",
       "      <th>X10357</th>\n",
       "      <th>X10431</th>\n",
       "      <th>X136542</th>\n",
       "      <th>X155060</th>\n",
       "      <th>X26823</th>\n",
       "      <th>X280660</th>\n",
       "      <th>X317712</th>\n",
       "      <th>...</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "      <th>event2</th>\n",
       "      <th>T2</th>\n",
       "      <th>event1</th>\n",
       "      <th>T1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>4.12</td>\n",
       "      <td>3.80</td>\n",
       "      <td>5.73</td>\n",
       "      <td>8.68</td>\n",
       "      <td>0</td>\n",
       "      <td>10.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.70</td>\n",
       "      <td>8.02</td>\n",
       "      <td>10.24</td>\n",
       "      <td>11.78</td>\n",
       "      <td>10.89</td>\n",
       "      <td>10.21</td>\n",
       "      <td>0</td>\n",
       "      <td>4047</td>\n",
       "      <td>1</td>\n",
       "      <td>1808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3.36</td>\n",
       "      <td>4.20</td>\n",
       "      <td>6.14</td>\n",
       "      <td>9.14</td>\n",
       "      <td>0</td>\n",
       "      <td>9.01</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.39</td>\n",
       "      <td>7.64</td>\n",
       "      <td>9.24</td>\n",
       "      <td>12.43</td>\n",
       "      <td>10.37</td>\n",
       "      <td>8.67</td>\n",
       "      <td>0</td>\n",
       "      <td>4005</td>\n",
       "      <td>0</td>\n",
       "      <td>4005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.93</td>\n",
       "      <td>3.66</td>\n",
       "      <td>3.35</td>\n",
       "      <td>7.28</td>\n",
       "      <td>10.41</td>\n",
       "      <td>0</td>\n",
       "      <td>9.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.59</td>\n",
       "      <td>8.38</td>\n",
       "      <td>9.06</td>\n",
       "      <td>12.41</td>\n",
       "      <td>9.88</td>\n",
       "      <td>9.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1474</td>\n",
       "      <td>0</td>\n",
       "      <td>1474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.32</td>\n",
       "      <td>3.87</td>\n",
       "      <td>6.85</td>\n",
       "      <td>9.66</td>\n",
       "      <td>0</td>\n",
       "      <td>8.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.13</td>\n",
       "      <td>4.07</td>\n",
       "      <td>9.29</td>\n",
       "      <td>12.01</td>\n",
       "      <td>9.85</td>\n",
       "      <td>10.05</td>\n",
       "      <td>0</td>\n",
       "      <td>1477</td>\n",
       "      <td>0</td>\n",
       "      <td>1477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>3.32</td>\n",
       "      <td>6.76</td>\n",
       "      <td>10.47</td>\n",
       "      <td>0</td>\n",
       "      <td>6.27</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.66</td>\n",
       "      <td>1.63</td>\n",
       "      <td>8.33</td>\n",
       "      <td>11.65</td>\n",
       "      <td>10.12</td>\n",
       "      <td>8.79</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.71</td>\n",
       "      <td>3.94</td>\n",
       "      <td>7.01</td>\n",
       "      <td>9.45</td>\n",
       "      <td>0</td>\n",
       "      <td>9.63</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.89</td>\n",
       "      <td>6.83</td>\n",
       "      <td>9.06</td>\n",
       "      <td>12.44</td>\n",
       "      <td>9.92</td>\n",
       "      <td>9.77</td>\n",
       "      <td>0</td>\n",
       "      <td>347</td>\n",
       "      <td>0</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>0.00</td>\n",
       "      <td>3.94</td>\n",
       "      <td>4.49</td>\n",
       "      <td>7.12</td>\n",
       "      <td>9.35</td>\n",
       "      <td>0</td>\n",
       "      <td>8.74</td>\n",
       "      <td>1.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.31</td>\n",
       "      <td>4.48</td>\n",
       "      <td>9.43</td>\n",
       "      <td>12.32</td>\n",
       "      <td>10.92</td>\n",
       "      <td>9.39</td>\n",
       "      <td>0</td>\n",
       "      <td>467</td>\n",
       "      <td>0</td>\n",
       "      <td>467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>0.00</td>\n",
       "      <td>4.54</td>\n",
       "      <td>4.82</td>\n",
       "      <td>6.03</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0</td>\n",
       "      <td>8.56</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.43</td>\n",
       "      <td>7.37</td>\n",
       "      <td>9.55</td>\n",
       "      <td>12.42</td>\n",
       "      <td>10.49</td>\n",
       "      <td>9.90</td>\n",
       "      <td>0</td>\n",
       "      <td>488</td>\n",
       "      <td>0</td>\n",
       "      <td>488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>0.00</td>\n",
       "      <td>1.71</td>\n",
       "      <td>3.05</td>\n",
       "      <td>6.43</td>\n",
       "      <td>10.16</td>\n",
       "      <td>0</td>\n",
       "      <td>7.98</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.64</td>\n",
       "      <td>5.73</td>\n",
       "      <td>8.99</td>\n",
       "      <td>12.70</td>\n",
       "      <td>9.56</td>\n",
       "      <td>9.55</td>\n",
       "      <td>0</td>\n",
       "      <td>3287</td>\n",
       "      <td>1</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>0.00</td>\n",
       "      <td>2.98</td>\n",
       "      <td>4.69</td>\n",
       "      <td>7.40</td>\n",
       "      <td>9.97</td>\n",
       "      <td>0</td>\n",
       "      <td>7.90</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.89</td>\n",
       "      <td>7.13</td>\n",
       "      <td>9.17</td>\n",
       "      <td>11.73</td>\n",
       "      <td>9.14</td>\n",
       "      <td>8.86</td>\n",
       "      <td>0</td>\n",
       "      <td>3256</td>\n",
       "      <td>0</td>\n",
       "      <td>3256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>692 rows Ã— 20535 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      X100130426  X100133144  X100134869  X10357  X10431  X136542  X155060  \\\n",
       "0           0.00        4.12        3.80    5.73    8.68        0    10.21   \n",
       "1           0.00        3.36        4.20    6.14    9.14        0     9.01   \n",
       "2           0.93        3.66        3.35    7.28   10.41        0     9.21   \n",
       "5           0.00        2.32        3.87    6.85    9.66        0     8.12   \n",
       "7           0.00        1.30        3.32    6.76   10.47        0     6.27   \n",
       "...          ...         ...         ...     ...     ...      ...      ...   \n",
       "1074        0.00        2.71        3.94    7.01    9.45        0     9.63   \n",
       "1077        0.00        3.94        4.49    7.12    9.35        0     8.74   \n",
       "1078        0.00        4.54        4.82    6.03    9.50        0     8.56   \n",
       "1079        0.00        1.71        3.05    6.43   10.16        0     7.98   \n",
       "1080        0.00        2.98        4.69    7.40    9.97        0     7.90   \n",
       "\n",
       "      X26823  X280660  X317712  ...   ZXDC  ZYG11A  ZYG11B    ZYX  ZZEF1  \\\n",
       "0       0.00     0.00      0.0  ...  10.70    8.02   10.24  11.78  10.89   \n",
       "1       1.06     0.63      0.0  ...  10.39    7.64    9.24  12.43  10.37   \n",
       "2       0.00     0.00      0.0  ...   9.59    8.38    9.06  12.41   9.88   \n",
       "5       0.00     0.00      0.0  ...  10.13    4.07    9.29  12.01   9.85   \n",
       "7       0.61     0.00      0.0  ...   9.66    1.63    8.33  11.65  10.12   \n",
       "...      ...      ...      ...  ...    ...     ...     ...    ...    ...   \n",
       "1074    0.56     0.00      0.0  ...   9.89    6.83    9.06  12.44   9.92   \n",
       "1077    1.91     0.00      0.0  ...  10.31    4.48    9.43  12.32  10.92   \n",
       "1078    0.56     0.00      0.0  ...  10.43    7.37    9.55  12.42  10.49   \n",
       "1079    0.68     0.00      0.0  ...   9.64    5.73    8.99  12.70   9.56   \n",
       "1080    0.43     0.00      0.0  ...   9.89    7.13    9.17  11.73   9.14   \n",
       "\n",
       "       ZZZ3  event2    T2  event1    T1  \n",
       "0     10.21       0  4047       1  1808  \n",
       "1      8.67       0  4005       0  4005  \n",
       "2      9.00       0  1474       0  1474  \n",
       "5     10.05       0  1477       0  1477  \n",
       "7      8.79       0   303       0   303  \n",
       "...     ...     ...   ...     ...   ...  \n",
       "1074   9.77       0   347       0   347  \n",
       "1077   9.39       0   467       0   467  \n",
       "1078   9.90       0   488       0   488  \n",
       "1079   9.55       0  3287       1   181  \n",
       "1080   8.86       0  3256       0  3256  \n",
       "\n",
       "[692 rows x 20535 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train/test/validation split\n",
    "df_test = df_train.sample(frac=0.2)\n",
    "df_train = df_train.drop(df_test.index)\n",
    "df_val = df_train.sample(frac=0.2)\n",
    "df_train = df_train.drop(df_val.index)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Covariate preprocessing\n",
    "cols_standardize =  xx.columns.tolist()\n",
    "\n",
    "standardize = [([col], StandardScaler()) for col in cols_standardize]\n",
    "\n",
    "x_mapper = DataFrameMapper(standardize)\n",
    "\n",
    "x_train = x_mapper.fit_transform(df_train).astype('float32')\n",
    "x_val = x_mapper.transform(df_val).astype('float32')\n",
    "x_test = x_mapper.transform(df_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretization of survival times\n",
    "class LabTransform(LabTransDiscreteTime):\n",
    "    def transform(self, durations, events):\n",
    "        durations, is_event = super().transform(durations, events > 0)\n",
    "        events[is_event == 0] = 0\n",
    "        return durations, events.astype('int64')\n",
    "        \n",
    "num_durations = 20\n",
    "\n",
    "labtrans1 = LabTransform(num_durations, scheme='equidistant')\n",
    "get_target1 = lambda df: (df['T1'].values, df['event1'].values)\n",
    "\n",
    "T1_train = labtrans1.fit_transform(*get_target1(df_train))\n",
    "T1_val = labtrans1.transform(*get_target1(df_val))\n",
    "T1_test, event1_test = labtrans1.transform(*get_target1(df_test))\n",
    "\n",
    "labtrans2 = LabTransform(num_durations, scheme='equidistant')\n",
    "get_target2 = lambda df: (df['T2'].values, df['event2'].values)\n",
    "\n",
    "T2_train = labtrans2.fit_transform(*get_target2(df_train))\n",
    "T2_val = labtrans2.transform(*get_target2(df_val))\n",
    "# Discretization is not required because the prediction time is already a continuous value after spline interpolation when evaluated on the test set\n",
    "T2_test, event2_test = get_target2(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Package the data into the input format required by the network later\n",
    "def index_to_1d(i, j, n):\n",
    "    \"\"\"\n",
    "    Converts a 2D index (i, j) from sets T1 and T2, each with elements ranging from 1 to n, to a 1D index.\n",
    "    \"\"\"\n",
    "    return i * n + j\n",
    "\n",
    "T_train = list(T1_train)\n",
    "T1_train_list = list(T1_train)\n",
    "T2_train_list = list(T2_train)\n",
    "T_train[0] = index_to_1d(T1_train_list[0], T2_train_list[0], num_durations)\n",
    "T_train[1] = index_to_1d(T1_train_list[1], T2_train_list[1], 2)\n",
    "T_train = tuple(T_train)\n",
    "\n",
    "T_val = list(T1_val)\n",
    "T1_val_list = list(T1_val)\n",
    "T2_val_list = list(T2_val)\n",
    "T_val[0] = index_to_1d(T1_val_list[0], T2_val_list[0], num_durations)\n",
    "T_val[1] = index_to_1d(T1_val_list[1], T2_val_list[1], 2)\n",
    "T_val = tuple(T_val)\n",
    "val = (x_val, T_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network architecture\n",
    "class Multivariate_survival(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, num_nodes_shared, num_nodes_indiv, num_T1,\n",
    "                 out_features, batch_norm=True, dropout=None):\n",
    "        super().__init__()\n",
    "        self.shared_net = tt.practical.MLPVanilla(\n",
    "            in_features, num_nodes_shared[:-1], num_nodes_shared[-1],\n",
    "            batch_norm, dropout,\n",
    "        )\n",
    "        self.risk_nets = torch.nn.ModuleList()\n",
    "        for _ in range(num_T1):\n",
    "            net = tt.practical.MLPVanilla(\n",
    "                num_nodes_shared[-1], num_nodes_indiv, out_features,\n",
    "                batch_norm, dropout,\n",
    "            )\n",
    "            self.risk_nets.append(net)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.shared_net(input)\n",
    "        out = [net(out) for net in self.risk_nets]\n",
    "        out = torch.stack(out, dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_features = x_train.shape[1]\n",
    "num_nodes_shared = [64, 64]\n",
    "num_nodes_indiv = [32, 32]\n",
    "num_T1 = num_durations \n",
    "out_features = len(labtrans2.cuts)\n",
    "batch_norm = True\n",
    "dropout = 0.7\n",
    "\n",
    "net = Multivariate_survival(in_features, num_nodes_shared, num_nodes_indiv, num_T1,\n",
    "                       out_features, batch_norm, dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class first_multi_task(tt.Model):\n",
    "\n",
    "    def __init__(self, net, optimizer=None, device=None, alpha=0.2, sigma=0.1, duration_index=None, loss=None):\n",
    "        self.duration_index = duration_index\n",
    "        if loss is None:\n",
    "            loss = Loss1(alpha, sigma)\n",
    "        super().__init__(net, loss, optimizer, device)\n",
    "\n",
    "    @property\n",
    "    def duration_index(self):\n",
    "        \n",
    "        return self._duration_index\n",
    "\n",
    "    @duration_index.setter\n",
    "    def duration_index(self, val):\n",
    "        self._duration_index = val\n",
    "\n",
    "    def make_dataloader(self, data, batch_size, shuffle, num_workers=0):\n",
    "        dataloader = super().make_dataloader(data, batch_size, shuffle, num_workers,\n",
    "                                             make_dataset=models.data.DeepHitDataset)\n",
    "        return dataloader\n",
    "    \n",
    "    def make_dataloader_predict(self, input, batch_size, shuffle=False, num_workers=0):\n",
    "        dataloader = super().make_dataloader(input, batch_size, shuffle, num_workers)\n",
    "        return dataloader\n",
    "\n",
    "    def predict_surv_df(self, input, batch_size=8224, eval_=True, num_workers=0):\n",
    "\n",
    "        surv = self.predict_pmf_1_cif_2(input, batch_size, True, eval_, True, num_workers)\n",
    "        return pd.DataFrame(surv, self.duration_index)\n",
    "\n",
    "    def predict_surv_2_condpmf_1(self, input, batch_size=8224, numpy=None, eval_=True,\n",
    "                     to_cpu=False, num_workers=0):\n",
    " \n",
    "        cif = self.predict_pmf_1_cif_2(input, batch_size, False, eval_, to_cpu, num_workers)\n",
    "        pmf = self.predict_pmf_1(input, batch_size, False, eval_, to_cpu, num_workers)\n",
    "        condsurv = 1. - cif/pmf\n",
    "        return tt.utils.array_or_tensor(condsurv, numpy, input)\n",
    "        \n",
    "    def predict_pmf_1_cif_2(self, input, batch_size=8224, numpy=None, eval_=True,\n",
    "                     to_cpu=False, num_workers=0):\n",
    " \n",
    "        pmf = self.predict_pmf_12(input, batch_size, False, eval_, to_cpu, num_workers)\n",
    "        cif = pmf.cumsum(1)\n",
    "        return tt.utils.array_or_tensor(cif, numpy, input) \n",
    "\n",
    "    def predict_pmf_1(self, input, batch_size=8224, numpy=None, eval_=True,\n",
    "                     to_cpu=False, num_workers=0):\n",
    " \n",
    "        pmf12 = self.predict_pmf_12(input, batch_size, False, eval_, to_cpu, num_workers)\n",
    "        pmf = pmf12.sum(1)\n",
    "        return tt.utils.array_or_tensor(pmf, numpy, input)\n",
    "    \n",
    "    def predict_pmf_12(self, input, batch_size=8224, numpy=None, eval_=True,\n",
    "                     to_cpu=False, num_workers=0):\n",
    " \n",
    "        preds = self.predict(input, batch_size, False, eval_, False, to_cpu, num_workers)\n",
    "        pmf = pad_col(preds.view(preds.size(0), -1)).softmax(1)[:, :-1]\n",
    "        pmf = pmf.view(preds.shape).transpose(0, 1).transpose(1, 2)\n",
    "        return tt.utils.array_or_tensor(pmf, numpy, input)\n",
    "\n",
    "def _reduction(loss: Tensor, reduction: str = 'mean') -> Tensor:\n",
    "    if reduction == 'none':\n",
    "        return loss\n",
    "    elif reduction == 'mean':\n",
    "        return loss.mean()\n",
    "    elif reduction == 'sum':\n",
    "        return loss.sum()\n",
    "    raise ValueError(f\"`reduction` = {reduction} is not valid. Use 'none', 'mean' or 'sum'.\")\n",
    "\n",
    "def _diff_cdf_at_time_i(pmf: Tensor, y: Tensor) -> Tensor:\n",
    "\n",
    "    n = pmf.shape[0]\n",
    "    ones = torch.ones((n, 1), device=pmf.device)\n",
    "    r = pmf.cumsum(1).matmul(y.transpose(0, 1))\n",
    "    diag_r = r.diag().view(1, -1)\n",
    "    r = ones.matmul(diag_r) - r\n",
    "    return r.transpose(0, 1)\n",
    "\n",
    "def _rank_loss_deephit(pmf: Tensor, y: Tensor, rank_mat: Tensor, sigma: float,\n",
    "                       reduction: str = 'mean') -> Tensor:\n",
    "\n",
    "    r = _diff_cdf_at_time_i(pmf, y)\n",
    "    loss = rank_mat * torch.exp(-r/sigma)\n",
    "    loss = loss.mean(1, keepdim=True)\n",
    "    return _reduction(loss, reduction)\n",
    "\n",
    "def index_from_1d(k, n):\n",
    "\n",
    "    i = k // n\n",
    "    j = k % n\n",
    "    return (i, j)\n",
    "    \n",
    "def nll_pmf_cr(phi: Tensor, idx_durations: Tensor, events: Tensor, reduction: str = 'mean',\n",
    "               epsilon: float = 1e-7) -> Tensor:\n",
    "\n",
    "    events = events.view(-1)\n",
    "    event_00 = (events == 0).float()\n",
    "    event_01 = (events == 1).float()\n",
    "    event_02 = (events == 2).float()\n",
    "    event_03 = (events == 3).float()\n",
    "    \n",
    "    idx_durations1, idx_durations2 = index_from_1d(idx_durations.view(-1), num_durations)\n",
    "    batch_size = phi.size(0)\n",
    "    sm = utils.pad_col(phi.view(batch_size, -1)).softmax(1)[:, :-1].view(phi.shape)\n",
    "    index = torch.arange(batch_size)\n",
    "    part1 = sm[index, idx_durations1, idx_durations2].relu().add(epsilon).log().mul(event_03)\n",
    "    part2 = (sm[index, idx_durations1, :].sum(1) - sm.cumsum(2)[index, idx_durations1, idx_durations2]).relu().add(epsilon).log().mul(event_02)\n",
    "    part3 = (sm[index, :, idx_durations2].sum(1) - sm.cumsum(1)[index, idx_durations1, idx_durations2]).relu().add(epsilon).log().mul(event_01)\n",
    "    part4 = (1 - sm.cumsum(2)[index, :, idx_durations2].sum(1) + sm.cumsum(1).cumsum(2)[index, idx_durations1, idx_durations2] - sm.cumsum(1)[index, idx_durations1, :].sum(1)).relu().add(epsilon).log().mul(event_00)     \n",
    "     \n",
    "    loss = - part1.add(part2).add(part3).add(part4)\n",
    "    return _reduction(loss, reduction)\n",
    "\n",
    "\n",
    "\n",
    "def rank_loss_deephit_cr(phi: Tensor, idx_durations: Tensor, events: Tensor, rank_mat: Tensor,\n",
    "                         sigma: float, reduction: str = 'mean') -> Tensor:\n",
    "\n",
    "    idx_durations = idx_durations.view(-1)\n",
    "    events = events.view(-1)\n",
    "    event_00 = (events == 0).float()\n",
    "    event_01 = (events == 1).float()\n",
    "    event_02 = (events == 2).float()\n",
    "    event_03 = (events == 3).float()\n",
    "\n",
    "    batch_size = phi.size(0)\n",
    "    pmf = utils.pad_col(phi.view(batch_size, -1)).softmax(1)[:, :-1].view(phi.shape)\n",
    "    y = torch.zeros_like(pmf)\n",
    "    y[torch.arange(batch_size), :, idx_durations] = 1.\n",
    "\n",
    "    loss = []\n",
    "    for i in range(4):\n",
    "        rank_loss_i = _rank_loss_deephit(pmf[:, i, :], y[:, i, :], rank_mat, sigma, 'none')\n",
    "        loss.append(rank_loss_i.view(-1) * (events == i).float())\n",
    "\n",
    "    if reduction == 'none':\n",
    "        return sum(loss)\n",
    "    elif reduction == 'mean':\n",
    "        return sum([lo.mean() for lo in loss])\n",
    "    elif reduction == 'sum':\n",
    "        return sum([lo.sum() for lo in loss])\n",
    "    return _reduction(loss, reduction)\n",
    "\n",
    "class _Loss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, reduction: str = 'mean') -> None:\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "\n",
    "class _Loss1(_Loss):\n",
    "\n",
    "    def __init__(self, alpha: float, sigma: float, reduction: str = 'mean') -> None:\n",
    "        super().__init__(reduction)\n",
    "        self.alpha = alpha\n",
    "        self.sigma = sigma\n",
    "\n",
    "    @property\n",
    "    def alpha(self) -> float:\n",
    "        return self._alpha\n",
    "\n",
    "    @alpha.setter\n",
    "    def alpha(self, alpha: float) -> None:\n",
    "        if (alpha < 0) or (alpha > 1):\n",
    "            raise ValueError(f\"Need `alpha` to be in [0, 1]. Got {alpha}.\")\n",
    "        self._alpha = alpha\n",
    "\n",
    "    @property\n",
    "    def sigma(self) -> float:\n",
    "        return self._sigma\n",
    "\n",
    "    @sigma.setter\n",
    "    def sigma(self, sigma: float) -> None:\n",
    "        if sigma <= 0:\n",
    "            raise ValueError(f\"Need `sigma` to be positive. Got {sigma}.\")\n",
    "        self._sigma = sigma\n",
    "\n",
    "class Loss1(_Loss1):\n",
    "\n",
    "    def forward(self, phi: Tensor, idx_durations: Tensor, events: Tensor, rank_mat: Tensor) -> Tensor:\n",
    "        nll =  nll_pmf_cr(phi, idx_durations, events, self.reduction)\n",
    "        return nll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tt.optim.AdamWR(lr=0.8, decoupled_weight_decay=0.01,\n",
    "                                    cycle_eta_multiplier=0.6)\n",
    "model = first_multi_task(net, optimizer, alpha=1,\n",
    "                   duration_index=labtrans1.cuts)\n",
    "batch_size = 128\n",
    "lrfind = model.lr_finder(x_train, T_train, batch_size, tolerance=50)\n",
    "model.optimizer.set_lr(lrfind.get_best_lr()) # The learning rates for the AdamWR optimizer were adjusted using the method proposed by Smith\n",
    "epochs = 512\n",
    "callbacks = [tt.callbacks.EarlyStoppingCycle()]\n",
    "verbose = False\n",
    "log = model.fit(x_train, T_train, batch_size, epochs, callbacks, verbose, val_data=val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-index: 0.7523214654098196\n",
      "IBS: 0.12050520406432358\n"
     ]
    }
   ],
   "source": [
    "# Spline interpolation and evaluation of predictive performance\n",
    "index = torch.arange(T1_test.size)\n",
    "x = np.linspace(0, num_durations-1, num_durations)\n",
    "\n",
    "xnew = np.linspace(0, num_durations-1, 10000)\n",
    "ynew=[]    \n",
    "for i in range(T2_test[event1_test==1].size):  \n",
    "    spline_interp = UnivariateSpline(x, (1. - (model.predict_pmf_12(x_test)[T1_test[event1_test==1],:,index[event1_test==1]].T\n",
    "                                               /model.predict_pmf_12(x_test)[T1_test[event1_test==1],:,index[event1_test==1]].sum(1)).cumsum(0))[:,i], s=0)\n",
    "    y_spline = spline_interp(xnew)\n",
    "    ynew.append(y_spline)\n",
    "        \n",
    "ynew_array = np.stack(ynew, axis=1)\n",
    "    \n",
    "surv1 = pd.DataFrame(ynew_array, np.linspace(0, labtrans2.cuts.max(), 10000))\n",
    "    \n",
    "ev1 = EvalSurv(surv1, np.array(T2_test[event1_test==1]), np.array(event2_test)[event1_test==1], censor_surv='km')\n",
    "\n",
    "ynew=[]\n",
    "\n",
    "for i in range(T2_test[event1_test==0].size):  \n",
    "    spline_interp = UnivariateSpline(x, (1-((model.predict_pmf_12(x_test).sum(0)[:,event1_test==0]-model.predict_pmf_12(x_test).cumsum(0)[T1_test[event1_test==0],:,index[event1_test==0]].T)\n",
    "                                            /(1-model.predict_pmf_12(x_test).cumsum(0)[T1_test[event1_test==0],:,index[event1_test==0]].sum(1))).cumsum(0))[:,i], s=0)\n",
    "    y_spline = spline_interp(xnew)\n",
    "    ynew.append(y_spline)\n",
    "\n",
    "ynew_array = np.stack(ynew, axis=1)\n",
    "    \n",
    "surv2 = pd.DataFrame(ynew_array, np.linspace(0, labtrans2.cuts.max(), 10000))\n",
    "\n",
    "ev2 = EvalSurv(surv2, np.array(T2_test[event1_test==0]), np.array(event2_test)[event1_test==0], censor_surv='km')\n",
    "\n",
    "time_grid = np.linspace(T2_test.min(), T2_test.max(), 100) \n",
    "\n",
    "C_index=(ev1.concordance_td()*T2_test[event1_test==1].size + ev2.concordance_td()*T2_test[event1_test==0].size)/T2_test.size\n",
    "\n",
    "IBS=(ev1.integrated_brier_score(time_grid)*T2_test[event1_test==1].size + ev2.integrated_brier_score(time_grid)*T2_test[event1_test==0].size)/T2_test.size\n",
    "\n",
    "print(\"C-index:\", C_index)\n",
    "print(\"IBS:\", IBS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
